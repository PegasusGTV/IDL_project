here!
Training:   0%|                                                                   | 0/17 [00:00<?, ?it/s]/jet/home/psamal/hw_envs/idl_hw4/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MeanAbsoluteError was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)  # noqa: B028
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00, 16.38it/s, batch_accuracy=20.00%, loss=0.0820, mae=nan]
Logging metrics: {'epoch': 1, 'train': {'train_loss': 0.1292960348861299, 'train_mae': nan, 'train_accuracy': 9.657794676806084}, 'val': {'val_loss': 0.06414933782695924, 'val_mae': 0.22437064349651337, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.1292960348861299, 'train_mae': nan, 'train_accuracy': 9.657794676806084}
splitting val
metrics {'val_loss': 0.06414933782695924, 'val_mae': 0.22437064349651337, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 0 Metrics:
  TRAIN      | train_loss: 0.1293 | train_mae: nan | train_accuracy: 9.6578
  VAL        | val_loss: 0.0641 | val_mae: 0.2244 | val_accuracy: 0.0000
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.56it/s, batch_accuracy=29.29%, loss=0.0587, mae=nan]
Logging metrics: {'epoch': 2, 'train': {'train_loss': 0.27330830946791307, 'train_mae': nan, 'train_accuracy': 5.114068441064639}, 'val': {'val_loss': 0.053525306734462715, 'val_mae': 0.20776048302650452, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.27330830946791307, 'train_mae': nan, 'train_accuracy': 5.114068441064639}
splitting val
metrics {'val_loss': 0.053525306734462715, 'val_mae': 0.20776048302650452, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 1 Metrics:
  TRAIN      | train_loss: 0.2733 | train_mae: nan | train_accuracy: 5.1141
  VAL        | val_loss: 0.0535 | val_mae: 0.2078 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.46it/s, batch_accuracy=7.14%, loss=0.1911, mae=nan]
Logging metrics: {'epoch': 3, 'train': {'train_loss': 0.3734761985875808, 'train_mae': nan, 'train_accuracy': 3.612167300380228}, 'val': {'val_loss': 0.535895879636675, 'val_mae': 0.6971864700317383, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.3734761985875808, 'train_mae': nan, 'train_accuracy': 3.612167300380228}
splitting val
metrics {'val_loss': 0.535895879636675, 'val_mae': 0.6971864700317383, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 2 Metrics:
  TRAIN      | train_loss: 0.3735 | train_mae: nan | train_accuracy: 3.6122
  VAL        | val_loss: 0.5359 | val_mae: 0.6972 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.12it/s, batch_accuracy=7.86%, loss=0.2061, mae=nan]
Logging metrics: {'epoch': 4, 'train': {'train_loss': 0.2822039974959631, 'train_mae': nan, 'train_accuracy': 4.011406844106464}, 'val': {'val_loss': 0.39700965113287806, 'val_mae': 0.5882587432861328, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.2822039974959631, 'train_mae': nan, 'train_accuracy': 4.011406844106464}
splitting val
metrics {'val_loss': 0.39700965113287806, 'val_mae': 0.5882587432861328, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 3 Metrics:
  TRAIN      | train_loss: 0.2822 | train_mae: nan | train_accuracy: 4.0114
  VAL        | val_loss: 0.3970 | val_mae: 0.5883 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.41it/s, batch_accuracy=17.86%, loss=0.0701, mae=nan]
Logging metrics: {'epoch': 5, 'train': {'train_loss': 0.10138124856432128, 'train_mae': nan, 'train_accuracy': 8.49809885931559}, 'val': {'val_loss': 0.20766074785450161, 'val_mae': 0.39549198746681213, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.10138124856432128, 'train_mae': nan, 'train_accuracy': 8.49809885931559}
splitting val
metrics {'val_loss': 0.20766074785450161, 'val_mae': 0.39549198746681213, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 4 Metrics:
  TRAIN      | train_loss: 0.1014 | train_mae: nan | train_accuracy: 8.4981
  VAL        | val_loss: 0.2077 | val_mae: 0.3955 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.22it/s, batch_accuracy=12.86%, loss=0.0996, mae=nan]
Logging metrics: {'epoch': 6, 'train': {'train_loss': 0.130494533326236, 'train_mae': nan, 'train_accuracy': 6.501901140684411}, 'val': {'val_loss': 0.2536019538872994, 'val_mae': 0.450773149728775, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.130494533326236, 'train_mae': nan, 'train_accuracy': 6.501901140684411}
splitting val
metrics {'val_loss': 0.2536019538872994, 'val_mae': 0.450773149728775, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 5 Metrics:
  TRAIN      | train_loss: 0.1305 | train_mae: nan | train_accuracy: 6.5019
  VAL        | val_loss: 0.2536 | val_mae: 0.4508 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.14it/s, batch_accuracy=10.00%, loss=0.1360, mae=nan]
Logging metrics: {'epoch': 7, 'train': {'train_loss': 0.17897460215898522, 'train_mae': nan, 'train_accuracy': 4.258555133079848}, 'val': {'val_loss': 0.31657730572975723, 'val_mae': 0.5159547328948975, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.17897460215898522, 'train_mae': nan, 'train_accuracy': 4.258555133079848}
splitting val
metrics {'val_loss': 0.31657730572975723, 'val_mae': 0.5159547328948975, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 6 Metrics:
  TRAIN      | train_loss: 0.1790 | train_mae: nan | train_accuracy: 4.2586
  VAL        | val_loss: 0.3166 | val_mae: 0.5160 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.63it/s, batch_accuracy=10.71%, loss=0.1135, mae=nan]
Logging metrics: {'epoch': 8, 'train': {'train_loss': 0.125137761773492, 'train_mae': nan, 'train_accuracy': 5.988593155893536}, 'val': {'val_loss': 0.22183699215818573, 'val_mae': 0.41361290216445923, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.125137761773492, 'train_mae': nan, 'train_accuracy': 5.988593155893536}
splitting val
metrics {'val_loss': 0.22183699215818573, 'val_mae': 0.41361290216445923, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 7 Metrics:
  TRAIN      | train_loss: 0.1251 | train_mae: nan | train_accuracy: 5.9886
  VAL        | val_loss: 0.2218 | val_mae: 0.4136 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.35it/s, batch_accuracy=25.00%, loss=0.0591, mae=nan]
Logging metrics: {'epoch': 9, 'train': {'train_loss': 0.08645102359042875, 'train_mae': nan, 'train_accuracy': 8.669201520912548}, 'val': {'val_loss': 0.19379290118313475, 'val_mae': 0.378758043050766, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08645102359042875, 'train_mae': nan, 'train_accuracy': 8.669201520912548}
splitting val
metrics {'val_loss': 0.19379290118313475, 'val_mae': 0.378758043050766, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 8 Metrics:
  TRAIN      | train_loss: 0.0865 | train_mae: nan | train_accuracy: 8.6692
  VAL        | val_loss: 0.1938 | val_mae: 0.3788 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.54it/s, batch_accuracy=5.71%, loss=0.1079, mae=nan]
Logging metrics: {'epoch': 10, 'train': {'train_loss': 0.11855921914142348, 'train_mae': nan, 'train_accuracy': 5.570342205323194}, 'val': {'val_loss': 0.22370243072509766, 'val_mae': 0.41666287183761597, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.11855921914142348, 'train_mae': nan, 'train_accuracy': 5.570342205323194}
splitting val
metrics {'val_loss': 0.22370243072509766, 'val_mae': 0.41666287183761597, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 9 Metrics:
  TRAIN      | train_loss: 0.1186 | train_mae: nan | train_accuracy: 5.5703
  VAL        | val_loss: 0.2237 | val_mae: 0.4167 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.27it/s, batch_accuracy=7.86%, loss=0.1007, mae=nan]
Logging metrics: {'epoch': 11, 'train': {'train_loss': 0.1150654991769972, 'train_mae': nan, 'train_accuracy': 5.722433460076045}, 'val': {'val_loss': 0.19204458614323763, 'val_mae': 0.37681400775909424, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.1150654991769972, 'train_mae': nan, 'train_accuracy': 5.722433460076045}
splitting val
metrics {'val_loss': 0.19204458614323763, 'val_mae': 0.37681400775909424, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 10 Metrics:
  TRAIN      | train_loss: 0.1151 | train_mae: nan | train_accuracy: 5.7224
  VAL        | val_loss: 0.1920 | val_mae: 0.3768 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.43it/s, batch_accuracy=13.57%, loss=0.0682, mae=nan]
Logging metrics: {'epoch': 12, 'train': {'train_loss': 0.08836744295100296, 'train_mae': nan, 'train_accuracy': 7.395437262357414}, 'val': {'val_loss': 0.19296618356000658, 'val_mae': 0.37838682532310486, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08836744295100296, 'train_mae': nan, 'train_accuracy': 7.395437262357414}
splitting val
metrics {'val_loss': 0.19296618356000658, 'val_mae': 0.37838682532310486, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 11 Metrics:
  TRAIN      | train_loss: 0.0884 | train_mae: nan | train_accuracy: 7.3954
  VAL        | val_loss: 0.1930 | val_mae: 0.3784 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.65it/s, batch_accuracy=10.00%, loss=0.0816, mae=nan]
Logging metrics: {'epoch': 13, 'train': {'train_loss': 0.11046251334504936, 'train_mae': nan, 'train_accuracy': 4.7908745247148286}, 'val': {'val_loss': 0.17542158697275506, 'val_mae': 0.35412970185279846, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.11046251334504936, 'train_mae': nan, 'train_accuracy': 4.7908745247148286}
splitting val
metrics {'val_loss': 0.17542158697275506, 'val_mae': 0.35412970185279846, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 12 Metrics:
  TRAIN      | train_loss: 0.1105 | train_mae: nan | train_accuracy: 4.7909
  VAL        | val_loss: 0.1754 | val_mae: 0.3541 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.60it/s, batch_accuracy=15.00%, loss=0.0617, mae=nan]
Logging metrics: {'epoch': 14, 'train': {'train_loss': 0.07766111999636821, 'train_mae': nan, 'train_accuracy': 7.984790874524715}, 'val': {'val_loss': 0.25090570937867135, 'val_mae': 0.4487314522266388, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07766111999636821, 'train_mae': nan, 'train_accuracy': 7.984790874524715}
splitting val
metrics {'val_loss': 0.25090570937867135, 'val_mae': 0.4487314522266388, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 13 Metrics:
  TRAIN      | train_loss: 0.0777 | train_mae: nan | train_accuracy: 7.9848
  VAL        | val_loss: 0.2509 | val_mae: 0.4487 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 43.91it/s, batch_accuracy=3.57%, loss=0.1128, mae=nan]
Logging metrics: {'epoch': 15, 'train': {'train_loss': 0.1429603180277937, 'train_mae': nan, 'train_accuracy': 3.935361216730038}, 'val': {'val_loss': 0.2588279631313862, 'val_mae': 0.4566088020801544, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.1429603180277937, 'train_mae': nan, 'train_accuracy': 3.935361216730038}
splitting val
metrics {'val_loss': 0.2588279631313862, 'val_mae': 0.4566088020801544, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 14 Metrics:
  TRAIN      | train_loss: 0.1430 | train_mae: nan | train_accuracy: 3.9354
  VAL        | val_loss: 0.2588 | val_mae: 0.4566 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.35it/s, batch_accuracy=18.57%, loss=0.0549, mae=nan]
Logging metrics: {'epoch': 16, 'train': {'train_loss': 0.06664871628406836, 'train_mae': nan, 'train_accuracy': 9.315589353612168}, 'val': {'val_loss': 0.27264834890429607, 'val_mae': 0.471991628408432, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.06664871628406836, 'train_mae': nan, 'train_accuracy': 9.315589353612168}
splitting val
metrics {'val_loss': 0.27264834890429607, 'val_mae': 0.471991628408432, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 15 Metrics:
  TRAIN      | train_loss: 0.0666 | train_mae: nan | train_accuracy: 9.3156
  VAL        | val_loss: 0.2726 | val_mae: 0.4720 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.53it/s, batch_accuracy=5.00%, loss=0.0822, mae=nan]
Logging metrics: {'epoch': 17, 'train': {'train_loss': 0.09924972649422889, 'train_mae': nan, 'train_accuracy': 5.494296577946768}, 'val': {'val_loss': 0.2655497237339916, 'val_mae': 0.46435546875, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.09924972649422889, 'train_mae': nan, 'train_accuracy': 5.494296577946768}
splitting val
metrics {'val_loss': 0.2655497237339916, 'val_mae': 0.46435546875, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 16 Metrics:
  TRAIN      | train_loss: 0.0992 | train_mae: nan | train_accuracy: 5.4943
  VAL        | val_loss: 0.2655 | val_mae: 0.4644 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.14it/s, batch_accuracy=11.43%, loss=0.0650, mae=nan]
Logging metrics: {'epoch': 18, 'train': {'train_loss': 0.07365898374368936, 'train_mae': nan, 'train_accuracy': 7.110266159695818}, 'val': {'val_loss': 0.2981718774609918, 'val_mae': 0.49871811270713806, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07365898374368936, 'train_mae': nan, 'train_accuracy': 7.110266159695818}
splitting val
metrics {'val_loss': 0.2981718774609918, 'val_mae': 0.49871811270713806, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 17 Metrics:
  TRAIN      | train_loss: 0.0737 | train_mae: nan | train_accuracy: 7.1103
  VAL        | val_loss: 0.2982 | val_mae: 0.4987 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.27it/s, batch_accuracy=22.14%, loss=0.0346, mae=nan]
Logging metrics: {'epoch': 19, 'train': {'train_loss': 0.09025111270381471, 'train_mae': nan, 'train_accuracy': 7.14828897338403}, 'val': {'val_loss': 0.08897144682455382, 'val_mae': 0.22458061575889587, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.09025111270381471, 'train_mae': nan, 'train_accuracy': 7.14828897338403}
splitting val
metrics {'val_loss': 0.08897144682455382, 'val_mae': 0.22458061575889587, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 18 Metrics:
  TRAIN      | train_loss: 0.0903 | train_mae: nan | train_accuracy: 7.1483
  VAL        | val_loss: 0.0890 | val_mae: 0.2246 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=44.29%, loss=0.0195, mae=nan]
Logging metrics: {'epoch': 20, 'train': {'train_loss': 0.11806565887177851, 'train_mae': nan, 'train_accuracy': 8.269961977186313}, 'val': {'val_loss': 0.049064148892492256, 'val_mae': 0.1908644288778305, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.11806565887177851, 'train_mae': nan, 'train_accuracy': 8.269961977186313}
splitting val
metrics {'val_loss': 0.049064148892492256, 'val_mae': 0.1908644288778305, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 19 Metrics:
  TRAIN      | train_loss: 0.1181 | train_mae: nan | train_accuracy: 8.2700
  VAL        | val_loss: 0.0491 | val_mae: 0.1909 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.36it/s, batch_accuracy=0.71%, loss=0.1493, mae=nan]
Logging metrics: {'epoch': 21, 'train': {'train_loss': 0.2736774981021881, 'train_mae': nan, 'train_accuracy': 2.870722433460076}, 'val': {'val_loss': 0.20502819750933038, 'val_mae': 0.39501282572746277, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.2736774981021881, 'train_mae': nan, 'train_accuracy': 2.870722433460076}
splitting val
metrics {'val_loss': 0.20502819750933038, 'val_mae': 0.39501282572746277, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 20 Metrics:
  TRAIN      | train_loss: 0.2737 | train_mae: nan | train_accuracy: 2.8707
  VAL        | val_loss: 0.2050 | val_mae: 0.3950 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.18it/s, batch_accuracy=0.00%, loss=0.1557, mae=nan]
Logging metrics: {'epoch': 22, 'train': {'train_loss': 0.16748120372286315, 'train_mae': nan, 'train_accuracy': 2.79467680608365}, 'val': {'val_loss': 0.2821362742641628, 'val_mae': 0.48207974433898926, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.16748120372286315, 'train_mae': nan, 'train_accuracy': 2.79467680608365}
splitting val
metrics {'val_loss': 0.2821362742641628, 'val_mae': 0.48207974433898926, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 21 Metrics:
  TRAIN      | train_loss: 0.1675 | train_mae: nan | train_accuracy: 2.7947
  VAL        | val_loss: 0.2821 | val_mae: 0.4821 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.21it/s, batch_accuracy=10.00%, loss=0.0534, mae=nan]
Logging metrics: {'epoch': 23, 'train': {'train_loss': 0.06007896863745646, 'train_mae': nan, 'train_accuracy': 6.93916349809886}, 'val': {'val_loss': 0.1401624733569638, 'val_mae': 0.3026929199695587, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.06007896863745646, 'train_mae': nan, 'train_accuracy': 6.93916349809886}
splitting val
metrics {'val_loss': 0.1401624733569638, 'val_mae': 0.3026929199695587, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 22 Metrics:
  TRAIN      | train_loss: 0.0601 | train_mae: nan | train_accuracy: 6.9392
  VAL        | val_loss: 0.1402 | val_mae: 0.3027 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.39it/s, batch_accuracy=3.57%, loss=0.0737, mae=nan]
Logging metrics: {'epoch': 24, 'train': {'train_loss': 0.08512203202728083, 'train_mae': nan, 'train_accuracy': 5.836501901140684}, 'val': {'val_loss': 0.15542512672059489, 'val_mae': 0.32659170031547546, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08512203202728083, 'train_mae': nan, 'train_accuracy': 5.836501901140684}
splitting val
metrics {'val_loss': 0.15542512672059489, 'val_mae': 0.32659170031547546, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 23 Metrics:
  TRAIN      | train_loss: 0.0851 | train_mae: nan | train_accuracy: 5.8365
  VAL        | val_loss: 0.1554 | val_mae: 0.3266 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.48it/s, batch_accuracy=2.86%, loss=0.0965, mae=nan]
Logging metrics: {'epoch': 25, 'train': {'train_loss': 0.10354738314228819, 'train_mae': nan, 'train_accuracy': 3.6692015209125475}, 'val': {'val_loss': 0.19877531304455442, 'val_mae': 0.3868092894554138, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.10354738314228819, 'train_mae': nan, 'train_accuracy': 3.6692015209125475}
splitting val
metrics {'val_loss': 0.19877531304455442, 'val_mae': 0.3868092894554138, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 24 Metrics:
  TRAIN      | train_loss: 0.1035 | train_mae: nan | train_accuracy: 3.6692
  VAL        | val_loss: 0.1988 | val_mae: 0.3868 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.35it/s, batch_accuracy=2.86%, loss=0.0697, mae=nan]
Logging metrics: {'epoch': 26, 'train': {'train_loss': 0.08018358323737243, 'train_mae': nan, 'train_accuracy': 5.057034220532319}, 'val': {'val_loss': 0.16613463047366814, 'val_mae': 0.34220370650291443, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08018358323737243, 'train_mae': nan, 'train_accuracy': 5.057034220532319}
splitting val
metrics {'val_loss': 0.16613463047366814, 'val_mae': 0.34220370650291443, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 25 Metrics:
  TRAIN      | train_loss: 0.0802 | train_mae: nan | train_accuracy: 5.0570
  VAL        | val_loss: 0.1661 | val_mae: 0.3422 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.23it/s, batch_accuracy=7.86%, loss=0.0656, mae=nan]
Logging metrics: {'epoch': 27, 'train': {'train_loss': 0.07646907619537056, 'train_mae': nan, 'train_accuracy': 5.8745247148288975}, 'val': {'val_loss': 0.14929179597220965, 'val_mae': 0.3180680572986603, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07646907619537056, 'train_mae': nan, 'train_accuracy': 5.8745247148288975}
splitting val
metrics {'val_loss': 0.14929179597220965, 'val_mae': 0.3180680572986603, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 26 Metrics:
  TRAIN      | train_loss: 0.0765 | train_mae: nan | train_accuracy: 5.8745
  VAL        | val_loss: 0.1493 | val_mae: 0.3181 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.12it/s, batch_accuracy=2.86%, loss=0.0826, mae=nan]
Logging metrics: {'epoch': 28, 'train': {'train_loss': 0.08951310691611396, 'train_mae': nan, 'train_accuracy': 4.600760456273764}, 'val': {'val_loss': 0.17313543462113246, 'val_mae': 0.3530968129634857, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08951310691611396, 'train_mae': nan, 'train_accuracy': 4.600760456273764}
splitting val
metrics {'val_loss': 0.17313543462113246, 'val_mae': 0.3530968129634857, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 27 Metrics:
  TRAIN      | train_loss: 0.0895 | train_mae: nan | train_accuracy: 4.6008
  VAL        | val_loss: 0.1731 | val_mae: 0.3531 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.26it/s, batch_accuracy=3.57%, loss=0.0768, mae=nan]
Logging metrics: {'epoch': 29, 'train': {'train_loss': 0.08267925158426336, 'train_mae': nan, 'train_accuracy': 5.171102661596958}, 'val': {'val_loss': 0.1665520554020901, 'val_mae': 0.34385502338409424, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08267925158426336, 'train_mae': nan, 'train_accuracy': 5.171102661596958}
splitting val
metrics {'val_loss': 0.1665520554020901, 'val_mae': 0.34385502338409424, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 28 Metrics:
  TRAIN      | train_loss: 0.0827 | train_mae: nan | train_accuracy: 5.1711
  VAL        | val_loss: 0.1666 | val_mae: 0.3439 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.33it/s, batch_accuracy=5.00%, loss=0.0658, mae=nan]
Logging metrics: {'epoch': 30, 'train': {'train_loss': 0.07658221617964284, 'train_mae': nan, 'train_accuracy': 6.178707224334601}, 'val': {'val_loss': 0.14584450513724512, 'val_mae': 0.31383848190307617, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07658221617964284, 'train_mae': nan, 'train_accuracy': 6.178707224334601}
splitting val
metrics {'val_loss': 0.14584450513724512, 'val_mae': 0.31383848190307617, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 29 Metrics:
  TRAIN      | train_loss: 0.0766 | train_mae: nan | train_accuracy: 6.1787
  VAL        | val_loss: 0.1458 | val_mae: 0.3138 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.32it/s, batch_accuracy=2.14%, loss=0.0697, mae=nan]
Logging metrics: {'epoch': 31, 'train': {'train_loss': 0.08638282797295785, 'train_mae': nan, 'train_accuracy': 5.152091254752852}, 'val': {'val_loss': 0.15989818108961887, 'val_mae': 0.3352876901626587, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08638282797295785, 'train_mae': nan, 'train_accuracy': 5.152091254752852}
splitting val
metrics {'val_loss': 0.15989818108961887, 'val_mae': 0.3352876901626587, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 30 Metrics:
  TRAIN      | train_loss: 0.0864 | train_mae: nan | train_accuracy: 5.1521
  VAL        | val_loss: 0.1599 | val_mae: 0.3353 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.49it/s, batch_accuracy=2.86%, loss=0.0720, mae=nan]
Logging metrics: {'epoch': 32, 'train': {'train_loss': 0.08557637922550788, 'train_mae': nan, 'train_accuracy': 5.019011406844107}, 'val': {'val_loss': 0.15607575142143557, 'val_mae': 0.32975733280181885, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08557637922550788, 'train_mae': nan, 'train_accuracy': 5.019011406844107}
splitting val
metrics {'val_loss': 0.15607575142143557, 'val_mae': 0.32975733280181885, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 31 Metrics:
  TRAIN      | train_loss: 0.0856 | train_mae: nan | train_accuracy: 5.0190
  VAL        | val_loss: 0.1561 | val_mae: 0.3298 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.51it/s, batch_accuracy=2.86%, loss=0.0597, mae=nan]
Logging metrics: {'epoch': 33, 'train': {'train_loss': 0.07660256140642294, 'train_mae': nan, 'train_accuracy': 5.475285171102661}, 'val': {'val_loss': 0.14097110367061308, 'val_mae': 0.30767425894737244, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07660256140642294, 'train_mae': nan, 'train_accuracy': 5.475285171102661}
splitting val
metrics {'val_loss': 0.14097110367061308, 'val_mae': 0.30767425894737244, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 32 Metrics:
  TRAIN      | train_loss: 0.0766 | train_mae: nan | train_accuracy: 5.4753
  VAL        | val_loss: 0.1410 | val_mae: 0.3077 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.57it/s, batch_accuracy=4.29%, loss=0.0754, mae=nan]
Logging metrics: {'epoch': 34, 'train': {'train_loss': 0.0863614802181494, 'train_mae': nan, 'train_accuracy': 5.0}, 'val': {'val_loss': 0.15666447309839646, 'val_mae': 0.3315941095352173, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.0863614802181494, 'train_mae': nan, 'train_accuracy': 5.0}
splitting val
metrics {'val_loss': 0.15666447309839646, 'val_mae': 0.3315941095352173, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 33 Metrics:
  TRAIN      | train_loss: 0.0864 | train_mae: nan | train_accuracy: 5.0000
  VAL        | val_loss: 0.1567 | val_mae: 0.3316 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.50it/s, batch_accuracy=5.00%, loss=0.0631, mae=nan]
Logging metrics: {'epoch': 35, 'train': {'train_loss': 0.07236938966091142, 'train_mae': nan, 'train_accuracy': 5.7034220532319395}, 'val': {'val_loss': 0.14225453478377936, 'val_mae': 0.3106194734573364, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07236938966091142, 'train_mae': nan, 'train_accuracy': 5.7034220532319395}
splitting val
metrics {'val_loss': 0.14225453478377936, 'val_mae': 0.3106194734573364, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 34 Metrics:
  TRAIN      | train_loss: 0.0724 | train_mae: nan | train_accuracy: 5.7034
  VAL        | val_loss: 0.1423 | val_mae: 0.3106 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.23it/s, batch_accuracy=5.00%, loss=0.0558, mae=nan]
Logging metrics: {'epoch': 36, 'train': {'train_loss': 0.07682948841398206, 'train_mae': nan, 'train_accuracy': 5.038022813688213}, 'val': {'val_loss': 0.14210587159899257, 'val_mae': 0.3107420802116394, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07682948841398206, 'train_mae': nan, 'train_accuracy': 5.038022813688213}
splitting val
metrics {'val_loss': 0.14210587159899257, 'val_mae': 0.3107420802116394, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 35 Metrics:
  TRAIN      | train_loss: 0.0768 | train_mae: nan | train_accuracy: 5.0380
  VAL        | val_loss: 0.1421 | val_mae: 0.3107 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.20it/s, batch_accuracy=1.43%, loss=0.0665, mae=nan]
Logging metrics: {'epoch': 37, 'train': {'train_loss': 0.06981181823595395, 'train_mae': nan, 'train_accuracy': 5.057034220532319}, 'val': {'val_loss': 0.13506172507401282, 'val_mae': 0.30088213086128235, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.06981181823595395, 'train_mae': nan, 'train_accuracy': 5.057034220532319}
splitting val
metrics {'val_loss': 0.13506172507401282, 'val_mae': 0.30088213086128235, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 36 Metrics:
  TRAIN      | train_loss: 0.0698 | train_mae: nan | train_accuracy: 5.0570
  VAL        | val_loss: 0.1351 | val_mae: 0.3009 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.00it/s, batch_accuracy=1.43%, loss=0.0658, mae=nan]
Logging metrics: {'epoch': 38, 'train': {'train_loss': 0.07825323307582181, 'train_mae': nan, 'train_accuracy': 4.695817490494297}, 'val': {'val_loss': 0.14847387283440405, 'val_mae': 0.32153812050819397, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.07825323307582181, 'train_mae': nan, 'train_accuracy': 4.695817490494297}
splitting val
metrics {'val_loss': 0.14847387283440405, 'val_mae': 0.32153812050819397, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 37 Metrics:
  TRAIN      | train_loss: 0.0783 | train_mae: nan | train_accuracy: 4.6958
  VAL        | val_loss: 0.1485 | val_mae: 0.3215 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.44it/s, batch_accuracy=12.14%, loss=0.0390, mae=nan]
Logging metrics: {'epoch': 39, 'train': {'train_loss': 0.055627492500801956, 'train_mae': nan, 'train_accuracy': 7.224334600760456}, 'val': {'val_loss': 0.11231035934198623, 'val_mae': 0.26535773277282715, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.055627492500801956, 'train_mae': nan, 'train_accuracy': 7.224334600760456}
splitting val
metrics {'val_loss': 0.11231035934198623, 'val_mae': 0.26535773277282715, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 38 Metrics:
  TRAIN      | train_loss: 0.0556 | train_mae: nan | train_accuracy: 7.2243
  VAL        | val_loss: 0.1123 | val_mae: 0.2654 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.48it/s, batch_accuracy=2.14%, loss=0.0718, mae=nan]
Logging metrics: {'epoch': 40, 'train': {'train_loss': 0.08926562426661357, 'train_mae': nan, 'train_accuracy': 3.688212927756654}, 'val': {'val_loss': 0.15706628761035485, 'val_mae': 0.3345101773738861, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08926562426661357, 'train_mae': nan, 'train_accuracy': 3.688212927756654}
splitting val
metrics {'val_loss': 0.15706628761035485, 'val_mae': 0.3345101773738861, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 39 Metrics:
  TRAIN      | train_loss: 0.0893 | train_mae: nan | train_accuracy: 3.6882
  VAL        | val_loss: 0.1571 | val_mae: 0.3345 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=28.57%, loss=0.0199, mae=nan]
Logging metrics: {'epoch': 41, 'train': {'train_loss': 0.04268565004826045, 'train_mae': nan, 'train_accuracy': 11.863117870722434}, 'val': {'val_loss': 0.0773212352655078, 'val_mae': 0.20839333534240723, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.04268565004826045, 'train_mae': nan, 'train_accuracy': 11.863117870722434}
splitting val
metrics {'val_loss': 0.0773212352655078, 'val_mae': 0.20839333534240723, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 40 Metrics:
  TRAIN      | train_loss: 0.0427 | train_mae: nan | train_accuracy: 11.8631
  VAL        | val_loss: 0.0773 | val_mae: 0.2084 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.19it/s, batch_accuracy=0.00%, loss=0.1122, mae=nan]
Logging metrics: {'epoch': 42, 'train': {'train_loss': 0.12364344494311075, 'train_mae': nan, 'train_accuracy': 2.5285171102661597}, 'val': {'val_loss': 0.196353631131601, 'val_mae': 0.3862517774105072, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.12364344494311075, 'train_mae': nan, 'train_accuracy': 2.5285171102661597}
splitting val
metrics {'val_loss': 0.196353631131601, 'val_mae': 0.3862517774105072, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 41 Metrics:
  TRAIN      | train_loss: 0.1236 | train_mae: nan | train_accuracy: 2.5285
  VAL        | val_loss: 0.1964 | val_mae: 0.3863 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.54it/s, batch_accuracy=53.57%, loss=0.0098, mae=nan]
Logging metrics: {'epoch': 43, 'train': {'train_loss': 0.04251767180066825, 'train_mae': nan, 'train_accuracy': 19.14448669201521}, 'val': {'val_loss': 0.06073028009209857, 'val_mae': 0.18763619661331177, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.04251767180066825, 'train_mae': nan, 'train_accuracy': 19.14448669201521}
splitting val
metrics {'val_loss': 0.06073028009209857, 'val_mae': 0.18763619661331177, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 42 Metrics:
  TRAIN      | train_loss: 0.0425 | train_mae: nan | train_accuracy: 19.1445
  VAL        | val_loss: 0.0607 | val_mae: 0.1876 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.08it/s, batch_accuracy=0.71%, loss=0.0763, mae=nan]
Logging metrics: {'epoch': 44, 'train': {'train_loss': 0.09080865931034994, 'train_mae': nan, 'train_accuracy': 4.467680608365019}, 'val': {'val_loss': 0.16285516671686365, 'val_mae': 0.3480773866176605, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.09080865931034994, 'train_mae': nan, 'train_accuracy': 4.467680608365019}
splitting val
metrics {'val_loss': 0.16285516671686365, 'val_mae': 0.3480773866176605, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 43 Metrics:
  TRAIN      | train_loss: 0.0908 | train_mae: nan | train_accuracy: 4.4677
  VAL        | val_loss: 0.1629 | val_mae: 0.3481 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.28it/s, batch_accuracy=1.43%, loss=0.0683, mae=nan]
Logging metrics: {'epoch': 45, 'train': {'train_loss': 0.08120386279807798, 'train_mae': nan, 'train_accuracy': 3.897338403041825}, 'val': {'val_loss': 0.17525854526750193, 'val_mae': 0.36265385150909424, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.08120386279807798, 'train_mae': nan, 'train_accuracy': 3.897338403041825}
splitting val
metrics {'val_loss': 0.17525854526750193, 'val_mae': 0.36265385150909424, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 44 Metrics:
  TRAIN      | train_loss: 0.0812 | train_mae: nan | train_accuracy: 3.8973
  VAL        | val_loss: 0.1753 | val_mae: 0.3627 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.37it/s, batch_accuracy=42.86%, loss=0.0140, mae=nan]
Logging metrics: {'epoch': 46, 'train': {'train_loss': 0.03002016275356251, 'train_mae': nan, 'train_accuracy': 15.70342205323194}, 'val': {'val_loss': 0.06626519300793642, 'val_mae': 0.1925862729549408, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.03002016275356251, 'train_mae': nan, 'train_accuracy': 15.70342205323194}
splitting val
metrics {'val_loss': 0.06626519300793642, 'val_mae': 0.1925862729549408, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 45 Metrics:
  TRAIN      | train_loss: 0.0300 | train_mae: nan | train_accuracy: 15.7034
  VAL        | val_loss: 0.0663 | val_mae: 0.1926 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.33it/s, batch_accuracy=3.57%, loss=0.0516, mae=nan]
Logging metrics: {'epoch': 47, 'train': {'train_loss': 0.06328273867699583, 'train_mae': nan, 'train_accuracy': 5.190114068441065}, 'val': {'val_loss': 0.12224177446141339, 'val_mae': 0.2892293334007263, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.06328273867699583, 'train_mae': nan, 'train_accuracy': 5.190114068441065}
splitting val
metrics {'val_loss': 0.12224177446141339, 'val_mae': 0.2892293334007263, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 46 Metrics:
  TRAIN      | train_loss: 0.0633 | train_mae: nan | train_accuracy: 5.1901
  VAL        | val_loss: 0.1222 | val_mae: 0.2892 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.54it/s, batch_accuracy=2.14%, loss=0.0602, mae=nan]
Logging metrics: {'epoch': 48, 'train': {'train_loss': 0.06984155677513931, 'train_mae': nan, 'train_accuracy': 4.7908745247148286}, 'val': {'val_loss': 0.14638756245574694, 'val_mae': 0.32442957162857056, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.06984155677513931, 'train_mae': nan, 'train_accuracy': 4.7908745247148286}
splitting val
metrics {'val_loss': 0.14638756245574694, 'val_mae': 0.32442957162857056, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 47 Metrics:
  TRAIN      | train_loss: 0.0698 | train_mae: nan | train_accuracy: 4.7909
  VAL        | val_loss: 0.1464 | val_mae: 0.3244 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.27it/s, batch_accuracy=60.71%, loss=0.0095, mae=nan]
Logging metrics: {'epoch': 49, 'train': {'train_loss': 0.026360723876992787, 'train_mae': nan, 'train_accuracy': 18.422053231939163}, 'val': {'val_loss': 0.05477164950746818, 'val_mae': 0.17660225927829742, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.026360723876992787, 'train_mae': nan, 'train_accuracy': 18.422053231939163}
splitting val
metrics {'val_loss': 0.05477164950746818, 'val_mae': 0.17660225927829742, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 48 Metrics:
  TRAIN      | train_loss: 0.0264 | train_mae: nan | train_accuracy: 18.4221
  VAL        | val_loss: 0.0548 | val_mae: 0.1766 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.21it/s, batch_accuracy=6.43%, loss=0.0396, mae=nan]
Logging metrics: {'epoch': 50, 'train': {'train_loss': 0.055705663213371774, 'train_mae': nan, 'train_accuracy': 5.6273764258555135}, 'val': {'val_loss': 0.10242218679229685, 'val_mae': 0.2584870755672455, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.055705663213371774, 'train_mae': nan, 'train_accuracy': 5.6273764258555135}
splitting val
metrics {'val_loss': 0.10242218679229685, 'val_mae': 0.2584870755672455, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 49 Metrics:
  TRAIN      | train_loss: 0.0557 | train_mae: nan | train_accuracy: 5.6274
  VAL        | val_loss: 0.1024 | val_mae: 0.2585 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.35it/s, batch_accuracy=10.71%, loss=0.0321, mae=nan]
Logging metrics: {'epoch': 51, 'train': {'train_loss': 0.04743334391781132, 'train_mae': nan, 'train_accuracy': 8.193916349809886}, 'val': {'val_loss': 0.10754822494599643, 'val_mae': 0.2688429355621338, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.04743334391781132, 'train_mae': nan, 'train_accuracy': 8.193916349809886}
splitting val
metrics {'val_loss': 0.10754822494599643, 'val_mae': 0.2688429355621338, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 50 Metrics:
  TRAIN      | train_loss: 0.0474 | train_mae: nan | train_accuracy: 8.1939
  VAL        | val_loss: 0.1075 | val_mae: 0.2688 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=39.29%, loss=0.0152, mae=nan]
Logging metrics: {'epoch': 52, 'train': {'train_loss': 0.029617246658233183, 'train_mae': nan, 'train_accuracy': 14.771863117870723}, 'val': {'val_loss': 0.05592823733619395, 'val_mae': 0.17634084820747375, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.029617246658233183, 'train_mae': nan, 'train_accuracy': 14.771863117870723}
splitting val
metrics {'val_loss': 0.05592823733619395, 'val_mae': 0.17634084820747375, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 51 Metrics:
  TRAIN      | train_loss: 0.0296 | train_mae: nan | train_accuracy: 14.7719
  VAL        | val_loss: 0.0559 | val_mae: 0.1763 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.56it/s, batch_accuracy=35.71%, loss=0.0180, mae=nan]
Logging metrics: {'epoch': 53, 'train': {'train_loss': 0.03406703802880905, 'train_mae': nan, 'train_accuracy': 12.85171102661597}, 'val': {'val_loss': 0.05887917914246553, 'val_mae': 0.18129436671733856, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.03406703802880905, 'train_mae': nan, 'train_accuracy': 12.85171102661597}
splitting val
metrics {'val_loss': 0.05887917914246553, 'val_mae': 0.18129436671733856, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 52 Metrics:
  TRAIN      | train_loss: 0.0341 | train_mae: nan | train_accuracy: 12.8517
  VAL        | val_loss: 0.0589 | val_mae: 0.1813 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.39it/s, batch_accuracy=16.43%, loss=0.0310, mae=nan]
Logging metrics: {'epoch': 54, 'train': {'train_loss': 0.04501851166495806, 'train_mae': nan, 'train_accuracy': 8.840304182509506}, 'val': {'val_loss': 0.07454282535402566, 'val_mae': 0.21193113923072815, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.04501851166495806, 'train_mae': nan, 'train_accuracy': 8.840304182509506}
splitting val
metrics {'val_loss': 0.07454282535402566, 'val_mae': 0.21193113923072815, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 53 Metrics:
  TRAIN      | train_loss: 0.0450 | train_mae: nan | train_accuracy: 8.8403
  VAL        | val_loss: 0.0745 | val_mae: 0.2119 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=60.71%, loss=0.0103, mae=nan]
Logging metrics: {'epoch': 55, 'train': {'train_loss': 0.02733342188761035, 'train_mae': nan, 'train_accuracy': 15.96958174904943}, 'val': {'val_loss': 0.039004223008683864, 'val_mae': 0.14990109205245972, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.02733342188761035, 'train_mae': nan, 'train_accuracy': 15.96958174904943}
splitting val
metrics {'val_loss': 0.039004223008683864, 'val_mae': 0.14990109205245972, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 54 Metrics:
  TRAIN      | train_loss: 0.0273 | train_mae: nan | train_accuracy: 15.9696
  VAL        | val_loss: 0.0390 | val_mae: 0.1499 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.53it/s, batch_accuracy=22.86%, loss=0.0220, mae=nan]
Logging metrics: {'epoch': 56, 'train': {'train_loss': 0.042392341880404, 'train_mae': nan, 'train_accuracy': 10.304182509505704}, 'val': {'val_loss': 0.0806106778999303, 'val_mae': 0.22971662878990173, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.042392341880404, 'train_mae': nan, 'train_accuracy': 10.304182509505704}
splitting val
metrics {'val_loss': 0.0806106778999303, 'val_mae': 0.22971662878990173, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 55 Metrics:
  TRAIN      | train_loss: 0.0424 | train_mae: nan | train_accuracy: 10.3042
  VAL        | val_loss: 0.0806 | val_mae: 0.2297 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 43.36it/s, batch_accuracy=55.00%, loss=0.0094, mae=nan]
Logging metrics: {'epoch': 57, 'train': {'train_loss': 0.027276403507918913, 'train_mae': nan, 'train_accuracy': 16.920152091254753}, 'val': {'val_loss': 0.032083587758493105, 'val_mae': 0.14247463643550873, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.027276403507918913, 'train_mae': nan, 'train_accuracy': 16.920152091254753}
splitting val
metrics {'val_loss': 0.032083587758493105, 'val_mae': 0.14247463643550873, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 56 Metrics:
  TRAIN      | train_loss: 0.0273 | train_mae: nan | train_accuracy: 16.9202
  VAL        | val_loss: 0.0321 | val_mae: 0.1425 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.41it/s, batch_accuracy=67.86%, loss=0.0067, mae=nan]
Logging metrics: {'epoch': 58, 'train': {'train_loss': 0.022053734997832728, 'train_mae': nan, 'train_accuracy': 18.897338403041825}, 'val': {'val_loss': 0.03145368167217946, 'val_mae': 0.13382713496685028, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.022053734997832728, 'train_mae': nan, 'train_accuracy': 18.897338403041825}
splitting val
metrics {'val_loss': 0.03145368167217946, 'val_mae': 0.13382713496685028, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 57 Metrics:
  TRAIN      | train_loss: 0.0221 | train_mae: nan | train_accuracy: 18.8973
  VAL        | val_loss: 0.0315 | val_mae: 0.1338 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.31it/s, batch_accuracy=23.57%, loss=0.0199, mae=nan]
Logging metrics: {'epoch': 59, 'train': {'train_loss': 0.038008293370670236, 'train_mae': nan, 'train_accuracy': 10.665399239543726}, 'val': {'val_loss': 0.05773170552397734, 'val_mae': 0.1842852085828781, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.038008293370670236, 'train_mae': nan, 'train_accuracy': 10.665399239543726}
splitting val
metrics {'val_loss': 0.05773170552397734, 'val_mae': 0.1842852085828781, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 58 Metrics:
  TRAIN      | train_loss: 0.0380 | train_mae: nan | train_accuracy: 10.6654
  VAL        | val_loss: 0.0577 | val_mae: 0.1843 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.34it/s, batch_accuracy=57.86%, loss=0.0096, mae=nan]
Logging metrics: {'epoch': 60, 'train': {'train_loss': 0.02294655052498833, 'train_mae': nan, 'train_accuracy': 20.399239543726235}, 'val': {'val_loss': 0.023923110016840415, 'val_mae': 0.13792067766189575, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.02294655052498833, 'train_mae': nan, 'train_accuracy': 20.399239543726235}
splitting val
metrics {'val_loss': 0.023923110016840415, 'val_mae': 0.13792067766189575, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 59 Metrics:
  TRAIN      | train_loss: 0.0229 | train_mae: nan | train_accuracy: 20.3992
  VAL        | val_loss: 0.0239 | val_mae: 0.1379 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.33it/s, batch_accuracy=57.86%, loss=0.0086, mae=nan]
Logging metrics: {'epoch': 61, 'train': {'train_loss': 0.03944175913150886, 'train_mae': nan, 'train_accuracy': 13.76425855513308}, 'val': {'val_loss': 0.05939623548480488, 'val_mae': 0.1934332251548767, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.03944175913150886, 'train_mae': nan, 'train_accuracy': 13.76425855513308}
splitting val
metrics {'val_loss': 0.05939623548480488, 'val_mae': 0.1934332251548767, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 60 Metrics:
  TRAIN      | train_loss: 0.0394 | train_mae: nan | train_accuracy: 13.7643
  VAL        | val_loss: 0.0594 | val_mae: 0.1934 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.46it/s, batch_accuracy=69.29%, loss=0.0057, mae=nan]
Logging metrics: {'epoch': 62, 'train': {'train_loss': 0.023787987489295778, 'train_mae': nan, 'train_accuracy': 19.049429657794676}, 'val': {'val_loss': 0.03203321693327603, 'val_mae': 0.13330532610416412, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.023787987489295778, 'train_mae': nan, 'train_accuracy': 19.049429657794676}
splitting val
metrics {'val_loss': 0.03203321693327603, 'val_mae': 0.13330532610416412, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 61 Metrics:
  TRAIN      | train_loss: 0.0238 | train_mae: nan | train_accuracy: 19.0494
  VAL        | val_loss: 0.0320 | val_mae: 0.1333 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=45.71%, loss=0.0118, mae=nan]
Logging metrics: {'epoch': 63, 'train': {'train_loss': 0.0315991954792985, 'train_mae': nan, 'train_accuracy': 14.866920152091256}, 'val': {'val_loss': 0.06879213872371905, 'val_mae': 0.22022469341754913, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.0315991954792985, 'train_mae': nan, 'train_accuracy': 14.866920152091256}
splitting val
metrics {'val_loss': 0.06879213872371905, 'val_mae': 0.22022469341754913, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 62 Metrics:
  TRAIN      | train_loss: 0.0316 | train_mae: nan | train_accuracy: 14.8669
  VAL        | val_loss: 0.0688 | val_mae: 0.2202 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.54it/s, batch_accuracy=60.00%, loss=0.0083, mae=nan]
Logging metrics: {'epoch': 64, 'train': {'train_loss': 0.017613658511536658, 'train_mae': nan, 'train_accuracy': 21.711026615969583}, 'val': {'val_loss': 0.018738961434804354, 'val_mae': 0.1037706583738327, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.017613658511536658, 'train_mae': nan, 'train_accuracy': 21.711026615969583}
splitting val
metrics {'val_loss': 0.018738961434804354, 'val_mae': 0.1037706583738327, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 63 Metrics:
  TRAIN      | train_loss: 0.0176 | train_mae: nan | train_accuracy: 21.7110
  VAL        | val_loss: 0.0187 | val_mae: 0.1038 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.25it/s, batch_accuracy=72.14%, loss=0.0054, mae=nan]
Logging metrics: {'epoch': 65, 'train': {'train_loss': 0.01994930515809431, 'train_mae': nan, 'train_accuracy': 19.315589353612168}, 'val': {'val_loss': 0.04092452940124793, 'val_mae': 0.15509577095508575, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.01994930515809431, 'train_mae': nan, 'train_accuracy': 19.315589353612168}
splitting val
metrics {'val_loss': 0.04092452940124793, 'val_mae': 0.15509577095508575, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 64 Metrics:
  TRAIN      | train_loss: 0.0199 | train_mae: nan | train_accuracy: 19.3156
  VAL        | val_loss: 0.0409 | val_mae: 0.1551 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 43.14it/s, batch_accuracy=35.00%, loss=0.0162, mae=nan]
Logging metrics: {'epoch': 66, 'train': {'train_loss': 0.018069214346914237, 'train_mae': nan, 'train_accuracy': 22.984790874524716}, 'val': {'val_loss': 0.012998789448866108, 'val_mae': 0.09757523238658905, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.018069214346914237, 'train_mae': nan, 'train_accuracy': 22.984790874524716}
splitting val
metrics {'val_loss': 0.012998789448866108, 'val_mae': 0.09757523238658905, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 65 Metrics:
  TRAIN      | train_loss: 0.0181 | train_mae: nan | train_accuracy: 22.9848
  VAL        | val_loss: 0.0130 | val_mae: 0.0976 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.19it/s, batch_accuracy=75.71%, loss=0.0044, mae=nan]
Logging metrics: {'epoch': 67, 'train': {'train_loss': 0.01838603151161861, 'train_mae': nan, 'train_accuracy': 20.5893536121673}, 'val': {'val_loss': 0.030548602292601694, 'val_mae': 0.13304346799850464, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.01838603151161861, 'train_mae': nan, 'train_accuracy': 20.5893536121673}
splitting val
metrics {'val_loss': 0.030548602292601694, 'val_mae': 0.13304346799850464, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 66 Metrics:
  TRAIN      | train_loss: 0.0184 | train_mae: nan | train_accuracy: 20.5894
  VAL        | val_loss: 0.0305 | val_mae: 0.1330 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.21it/s, batch_accuracy=30.71%, loss=0.0218, mae=nan]
Logging metrics: {'epoch': 68, 'train': {'train_loss': 0.019921068994491274, 'train_mae': nan, 'train_accuracy': 25.85551330798479}, 'val': {'val_loss': 0.014860573268476748, 'val_mae': 0.10805342346429825, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.019921068994491274, 'train_mae': nan, 'train_accuracy': 25.85551330798479}
splitting val
metrics {'val_loss': 0.014860573268476748, 'val_mae': 0.10805342346429825, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 67 Metrics:
  TRAIN      | train_loss: 0.0199 | train_mae: nan | train_accuracy: 25.8555
  VAL        | val_loss: 0.0149 | val_mae: 0.1081 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 43.67it/s, batch_accuracy=55.00%, loss=0.0079, mae=nan]
Logging metrics: {'epoch': 69, 'train': {'train_loss': 0.02914742914740237, 'train_mae': nan, 'train_accuracy': 16.577946768060837}, 'val': {'val_loss': 0.04478949373400452, 'val_mae': 0.15939544141292572, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.02914742914740237, 'train_mae': nan, 'train_accuracy': 16.577946768060837}
splitting val
metrics {'val_loss': 0.04478949373400452, 'val_mae': 0.15939544141292572, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 68 Metrics:
  TRAIN      | train_loss: 0.0291 | train_mae: nan | train_accuracy: 16.5779
  VAL        | val_loss: 0.0448 | val_mae: 0.1594 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.14it/s, batch_accuracy=27.14%, loss=0.0245, mae=nan]
Logging metrics: {'epoch': 70, 'train': {'train_loss': 0.0218230159492887, 'train_mae': nan, 'train_accuracy': 25.475285171102662}, 'val': {'val_loss': 0.01955423314099344, 'val_mae': 0.12238771468400955, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.0218230159492887, 'train_mae': nan, 'train_accuracy': 25.475285171102662}
splitting val
metrics {'val_loss': 0.01955423314099344, 'val_mae': 0.12238771468400955, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 69 Metrics:
  TRAIN      | train_loss: 0.0218 | train_mae: nan | train_accuracy: 25.4753
  VAL        | val_loss: 0.0196 | val_mae: 0.1224 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.62it/s, batch_accuracy=67.86%, loss=0.0068, mae=nan]
Logging metrics: {'epoch': 71, 'train': {'train_loss': 0.026129139041945963, 'train_mae': nan, 'train_accuracy': 17.30038022813688}, 'val': {'val_loss': 0.030916821436593998, 'val_mae': 0.13226905465126038, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.026129139041945963, 'train_mae': nan, 'train_accuracy': 17.30038022813688}
splitting val
metrics {'val_loss': 0.030916821436593998, 'val_mae': 0.13226905465126038, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 70 Metrics:
  TRAIN      | train_loss: 0.0261 | train_mae: nan | train_accuracy: 17.3004
  VAL        | val_loss: 0.0309 | val_mae: 0.1323 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=55.71%, loss=0.0088, mae=nan]
Logging metrics: {'epoch': 72, 'train': {'train_loss': 0.015272446061721772, 'train_mae': nan, 'train_accuracy': 24.125475285171103}, 'val': {'val_loss': 0.012880172330461093, 'val_mae': 0.09960562735795975, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.015272446061721772, 'train_mae': nan, 'train_accuracy': 24.125475285171103}
splitting val
metrics {'val_loss': 0.012880172330461093, 'val_mae': 0.09960562735795975, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 71 Metrics:
  TRAIN      | train_loss: 0.0153 | train_mae: nan | train_accuracy: 24.1255
  VAL        | val_loss: 0.0129 | val_mae: 0.0996 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.12it/s, batch_accuracy=66.43%, loss=0.0071, mae=nan]
Logging metrics: {'epoch': 73, 'train': {'train_loss': 0.023079213753569264, 'train_mae': nan, 'train_accuracy': 17.69961977186312}, 'val': {'val_loss': 0.0270839359036228, 'val_mae': 0.12384586036205292, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.023079213753569264, 'train_mae': nan, 'train_accuracy': 17.69961977186312}
splitting val
metrics {'val_loss': 0.0270839359036228, 'val_mae': 0.12384586036205292, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 72 Metrics:
  TRAIN      | train_loss: 0.0231 | train_mae: nan | train_accuracy: 17.6996
  VAL        | val_loss: 0.0271 | val_mae: 0.1238 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.18it/s, batch_accuracy=49.29%, loss=0.0116, mae=nan]
Logging metrics: {'epoch': 74, 'train': {'train_loss': 0.012689458776421194, 'train_mae': nan, 'train_accuracy': 26.44486692015209}, 'val': {'val_loss': 0.010411594475575742, 'val_mae': 0.08764667063951492, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.012689458776421194, 'train_mae': nan, 'train_accuracy': 26.44486692015209}
splitting val
metrics {'val_loss': 0.010411594475575742, 'val_mae': 0.08764667063951492, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 73 Metrics:
  TRAIN      | train_loss: 0.0127 | train_mae: nan | train_accuracy: 26.4449
  VAL        | val_loss: 0.0104 | val_mae: 0.0876 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.43it/s, batch_accuracy=65.00%, loss=0.0073, mae=nan]
Logging metrics: {'epoch': 75, 'train': {'train_loss': 0.01274397455070862, 'train_mae': nan, 'train_accuracy': 21.50190114068441}, 'val': {'val_loss': 0.014817446445258672, 'val_mae': 0.1049695760011673, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.01274397455070862, 'train_mae': nan, 'train_accuracy': 21.50190114068441}
splitting val
metrics {'val_loss': 0.014817446445258672, 'val_mae': 0.1049695760011673, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 74 Metrics:
  TRAIN      | train_loss: 0.0127 | train_mae: nan | train_accuracy: 21.5019
  VAL        | val_loss: 0.0148 | val_mae: 0.1050 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.31it/s, batch_accuracy=27.14%, loss=0.0239, mae=nan]
Logging metrics: {'epoch': 76, 'train': {'train_loss': 0.018115635139747264, 'train_mae': nan, 'train_accuracy': 21.50190114068441}, 'val': {'val_loss': 0.024042449469659354, 'val_mae': 0.13382190465927124, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.018115635139747264, 'train_mae': nan, 'train_accuracy': 21.50190114068441}
splitting val
metrics {'val_loss': 0.024042449469659354, 'val_mae': 0.13382190465927124, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 75 Metrics:
  TRAIN      | train_loss: 0.0181 | train_mae: nan | train_accuracy: 21.5019
  VAL        | val_loss: 0.0240 | val_mae: 0.1338 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.34it/s, batch_accuracy=72.86%, loss=0.0052, mae=nan]
Logging metrics: {'epoch': 77, 'train': {'train_loss': 0.01367153567102642, 'train_mae': nan, 'train_accuracy': 26.045627376425855}, 'val': {'val_loss': 0.019929587953542702, 'val_mae': 0.12491189688444138, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.01367153567102642, 'train_mae': nan, 'train_accuracy': 26.045627376425855}
splitting val
metrics {'val_loss': 0.019929587953542702, 'val_mae': 0.12491189688444138, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 76 Metrics:
  TRAIN      | train_loss: 0.0137 | train_mae: nan | train_accuracy: 26.0456
  VAL        | val_loss: 0.0199 | val_mae: 0.1249 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.10it/s, batch_accuracy=43.57%, loss=0.0137, mae=nan]
Logging metrics: {'epoch': 78, 'train': {'train_loss': 0.016055107888670022, 'train_mae': nan, 'train_accuracy': 21.482889733840302}, 'val': {'val_loss': 0.016025766167764695, 'val_mae': 0.10973186790943146, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.016055107888670022, 'train_mae': nan, 'train_accuracy': 21.482889733840302}
splitting val
metrics {'val_loss': 0.016025766167764695, 'val_mae': 0.10973186790943146, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 77 Metrics:
  TRAIN      | train_loss: 0.0161 | train_mae: nan | train_accuracy: 21.4829
  VAL        | val_loss: 0.0160 | val_mae: 0.1097 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 43.78it/s, batch_accuracy=50.00%, loss=0.0092, mae=nan]
Logging metrics: {'epoch': 79, 'train': {'train_loss': 0.029337690781957748, 'train_mae': nan, 'train_accuracy': 15.931558935361217}, 'val': {'val_loss': 0.024316055712683887, 'val_mae': 0.11802472919225693, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.029337690781957748, 'train_mae': nan, 'train_accuracy': 15.931558935361217}
splitting val
metrics {'val_loss': 0.024316055712683887, 'val_mae': 0.11802472919225693, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 78 Metrics:
  TRAIN      | train_loss: 0.0293 | train_mae: nan | train_accuracy: 15.9316
  VAL        | val_loss: 0.0243 | val_mae: 0.1180 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.30it/s, batch_accuracy=62.86%, loss=0.0070, mae=nan]
Logging metrics: {'epoch': 80, 'train': {'train_loss': 0.014345564096882769, 'train_mae': nan, 'train_accuracy': 28.155893536121674}, 'val': {'val_loss': 0.007804021995589637, 'val_mae': 0.07635807991027832, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.014345564096882769, 'train_mae': nan, 'train_accuracy': 28.155893536121674}
splitting val
metrics {'val_loss': 0.007804021995589637, 'val_mae': 0.07635807991027832, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 79 Metrics:
  TRAIN      | train_loss: 0.0143 | train_mae: nan | train_accuracy: 28.1559
  VAL        | val_loss: 0.0078 | val_mae: 0.0764 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.31it/s, batch_accuracy=85.00%, loss=0.0033, mae=nan]
Logging metrics: {'epoch': 81, 'train': {'train_loss': 0.017348174940610566, 'train_mae': nan, 'train_accuracy': 20.53231939163498}, 'val': {'val_loss': 0.013637037835265165, 'val_mae': 0.09390736371278763, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.017348174940610566, 'train_mae': nan, 'train_accuracy': 20.53231939163498}
splitting val
metrics {'val_loss': 0.013637037835265165, 'val_mae': 0.09390736371278763, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 80 Metrics:
  TRAIN      | train_loss: 0.0173 | train_mae: nan | train_accuracy: 20.5323
  VAL        | val_loss: 0.0136 | val_mae: 0.0939 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.34it/s, batch_accuracy=22.14%, loss=0.0245, mae=nan]
Logging metrics: {'epoch': 82, 'train': {'train_loss': 0.02157124757285127, 'train_mae': nan, 'train_accuracy': 18.269961977186313}, 'val': {'val_loss': 0.019132551449607283, 'val_mae': 0.11927789449691772, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.02157124757285127, 'train_mae': nan, 'train_accuracy': 18.269961977186313}
splitting val
metrics {'val_loss': 0.019132551449607283, 'val_mae': 0.11927789449691772, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 81 Metrics:
  TRAIN      | train_loss: 0.0216 | train_mae: nan | train_accuracy: 18.2700
  VAL        | val_loss: 0.0191 | val_mae: 0.1193 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.28it/s, batch_accuracy=67.86%, loss=0.0066, mae=nan]
Logging metrics: {'epoch': 83, 'train': {'train_loss': 0.011961619830035212, 'train_mae': nan, 'train_accuracy': 26.140684410646386}, 'val': {'val_loss': 0.024235163796568076, 'val_mae': 0.13542163372039795, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.011961619830035212, 'train_mae': nan, 'train_accuracy': 26.140684410646386}
splitting val
metrics {'val_loss': 0.024235163796568076, 'val_mae': 0.13542163372039795, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 82 Metrics:
  TRAIN      | train_loss: 0.0120 | train_mae: nan | train_accuracy: 26.1407
  VAL        | val_loss: 0.0242 | val_mae: 0.1354 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.36it/s, batch_accuracy=18.57%, loss=0.0256, mae=nan]
Logging metrics: {'epoch': 84, 'train': {'train_loss': 0.02239994844952917, 'train_mae': nan, 'train_accuracy': 21.520912547528518}, 'val': {'val_loss': 0.03384942953137293, 'val_mae': 0.16160808503627777, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.02239994844952917, 'train_mae': nan, 'train_accuracy': 21.520912547528518}
splitting val
metrics {'val_loss': 0.03384942953137293, 'val_mae': 0.16160808503627777, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 83 Metrics:
  TRAIN      | train_loss: 0.0224 | train_mae: nan | train_accuracy: 21.5209
  VAL        | val_loss: 0.0338 | val_mae: 0.1616 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.45it/s, batch_accuracy=49.29%, loss=0.0097, mae=nan]
/jet/home/psamal/hw_envs/idl_hw4/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Logging metrics: {'epoch': 85, 'train': {'train_loss': 0.03378552350679505, 'train_mae': nan, 'train_accuracy': 13.403041825095057}, 'val': {'val_loss': 0.01920190493532475, 'val_mae': 0.10559454560279846, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.03378552350679505, 'train_mae': nan, 'train_accuracy': 13.403041825095057}
splitting val
metrics {'val_loss': 0.01920190493532475, 'val_mae': 0.10559454560279846, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 84 Metrics:
  TRAIN      | train_loss: 0.0338 | train_mae: nan | train_accuracy: 13.4030
  VAL        | val_loss: 0.0192 | val_mae: 0.1056 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.69it/s, batch_accuracy=79.29%, loss=0.0042, mae=nan]
Logging metrics: {'epoch': 86, 'train': {'train_loss': 0.01476840676647742, 'train_mae': nan, 'train_accuracy': 21.40684410646388}, 'val': {'val_loss': 0.006764293338903445, 'val_mae': 0.07038488239049911, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.01476840676647742, 'train_mae': nan, 'train_accuracy': 21.40684410646388}
splitting val
metrics {'val_loss': 0.006764293338903445, 'val_mae': 0.07038488239049911, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 85 Metrics:
  TRAIN      | train_loss: 0.0148 | train_mae: nan | train_accuracy: 21.4068
  VAL        | val_loss: 0.0068 | val_mae: 0.0704 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.26it/s, batch_accuracy=67.86%, loss=0.0062, mae=nan]
Logging metrics: {'epoch': 87, 'train': {'train_loss': 0.02043807652810794, 'train_mae': nan, 'train_accuracy': 18.878326996197718}, 'val': {'val_loss': 0.012235931927125725, 'val_mae': 0.08713993430137634, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.02043807652810794, 'train_mae': nan, 'train_accuracy': 18.878326996197718}
splitting val
metrics {'val_loss': 0.012235931927125725, 'val_mae': 0.08713993430137634, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 86 Metrics:
  TRAIN      | train_loss: 0.0204 | train_mae: nan | train_accuracy: 18.8783
  VAL        | val_loss: 0.0122 | val_mae: 0.0871 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.02it/s, batch_accuracy=55.00%, loss=0.0089, mae=nan]
Logging metrics: {'epoch': 88, 'train': {'train_loss': 0.012138876260148482, 'train_mae': nan, 'train_accuracy': 30.342205323193916}, 'val': {'val_loss': 0.004141068354799044, 'val_mae': 0.0530216209590435, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.012138876260148482, 'train_mae': nan, 'train_accuracy': 30.342205323193916}
splitting val
metrics {'val_loss': 0.004141068354799044, 'val_mae': 0.0530216209590435, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 87 Metrics:
  TRAIN      | train_loss: 0.0121 | train_mae: nan | train_accuracy: 30.3422
  VAL        | val_loss: 0.0041 | val_mae: 0.0530 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 43.29it/s, batch_accuracy=36.43%, loss=0.0116, mae=nan]
Logging metrics: {'epoch': 89, 'train': {'train_loss': 0.01224224350836567, 'train_mae': nan, 'train_accuracy': 19.08745247148289}, 'val': {'val_loss': 0.01887731540373108, 'val_mae': 0.11751185357570648, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.01224224350836567, 'train_mae': nan, 'train_accuracy': 19.08745247148289}
splitting val
metrics {'val_loss': 0.01887731540373108, 'val_mae': 0.11751185357570648, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 88 Metrics:
  TRAIN      | train_loss: 0.0122 | train_mae: nan | train_accuracy: 19.0875
  VAL        | val_loss: 0.0189 | val_mae: 0.1175 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.68it/s, batch_accuracy=17.86%, loss=0.0297, mae=nan]
Logging metrics: {'epoch': 90, 'train': {'train_loss': 0.031678918479966574, 'train_mae': nan, 'train_accuracy': 20.70342205323194}, 'val': {'val_loss': 0.030678727385906764, 'val_mae': 0.15959532558918, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.031678918479966574, 'train_mae': nan, 'train_accuracy': 20.70342205323194}
splitting val
metrics {'val_loss': 0.030678727385906764, 'val_mae': 0.15959532558918, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 89 Metrics:
  TRAIN      | train_loss: 0.0317 | train_mae: nan | train_accuracy: 20.7034
  VAL        | val_loss: 0.0307 | val_mae: 0.1596 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.36it/s, batch_accuracy=75.00%, loss=0.0055, mae=nan]
Logging metrics: {'epoch': 91, 'train': {'train_loss': 0.024192825058907158, 'train_mae': nan, 'train_accuracy': 20.627376425855513}, 'val': {'val_loss': 0.016353381185123583, 'val_mae': 0.10247248411178589, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.024192825058907158, 'train_mae': nan, 'train_accuracy': 20.627376425855513}
splitting val
metrics {'val_loss': 0.016353381185123583, 'val_mae': 0.10247248411178589, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 90 Metrics:
  TRAIN      | train_loss: 0.0242 | train_mae: nan | train_accuracy: 20.6274
  VAL        | val_loss: 0.0164 | val_mae: 0.1025 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.71it/s, batch_accuracy=55.00%, loss=0.0084, mae=nan]
Logging metrics: {'epoch': 92, 'train': {'train_loss': 0.013595575342811786, 'train_mae': nan, 'train_accuracy': 24.20152091254753}, 'val': {'val_loss': 0.020686373668535294, 'val_mae': 0.12521634995937347, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.013595575342811786, 'train_mae': nan, 'train_accuracy': 24.20152091254753}
splitting val
metrics {'val_loss': 0.020686373668535294, 'val_mae': 0.12521634995937347, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 91 Metrics:
  TRAIN      | train_loss: 0.0136 | train_mae: nan | train_accuracy: 24.2015
  VAL        | val_loss: 0.0207 | val_mae: 0.1252 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=70.71%, loss=0.0055, mae=nan]
Logging metrics: {'epoch': 93, 'train': {'train_loss': 0.017797255114839896, 'train_mae': nan, 'train_accuracy': 20.456273764258555}, 'val': {'val_loss': 0.005182027054213037, 'val_mae': 0.05842862278223038, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.017797255114839896, 'train_mae': nan, 'train_accuracy': 20.456273764258555}
splitting val
metrics {'val_loss': 0.005182027054213037, 'val_mae': 0.05842862278223038, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 92 Metrics:
  TRAIN      | train_loss: 0.0178 | train_mae: nan | train_accuracy: 20.4563
  VAL        | val_loss: 0.0052 | val_mae: 0.0584 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.26it/s, batch_accuracy=76.43%, loss=0.0045, mae=nan]
Logging metrics: {'epoch': 94, 'train': {'train_loss': 0.009017828111837798, 'train_mae': nan, 'train_accuracy': 30.79847908745247}, 'val': {'val_loss': 0.00287804163479865, 'val_mae': 0.04356792941689491, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.009017828111837798, 'train_mae': nan, 'train_accuracy': 30.79847908745247}
splitting val
metrics {'val_loss': 0.00287804163479865, 'val_mae': 0.04356792941689491, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 93 Metrics:
  TRAIN      | train_loss: 0.0090 | train_mae: nan | train_accuracy: 30.7985
  VAL        | val_loss: 0.0029 | val_mae: 0.0436 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.38it/s, batch_accuracy=69.29%, loss=0.0060, mae=nan]
Logging metrics: {'epoch': 95, 'train': {'train_loss': 0.006838320441076624, 'train_mae': nan, 'train_accuracy': 35.627376425855516}, 'val': {'val_loss': 0.00260391533562301, 'val_mae': 0.040508970618247986, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.006838320441076624, 'train_mae': nan, 'train_accuracy': 35.627376425855516}
splitting val
metrics {'val_loss': 0.00260391533562301, 'val_mae': 0.040508970618247986, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 94 Metrics:
  TRAIN      | train_loss: 0.0068 | train_mae: nan | train_accuracy: 35.6274
  VAL        | val_loss: 0.0026 | val_mae: 0.0405 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.13it/s, batch_accuracy=15.71%, loss=0.0277, mae=nan]
Logging metrics: {'epoch': 96, 'train': {'train_loss': 0.018385642254193927, 'train_mae': nan, 'train_accuracy': 10.342205323193916}, 'val': {'val_loss': 0.04267707010793606, 'val_mae': 0.19839069247245789, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.018385642254193927, 'train_mae': nan, 'train_accuracy': 10.342205323193916}
splitting val
metrics {'val_loss': 0.04267707010793606, 'val_mae': 0.19839069247245789, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 95 Metrics:
  TRAIN      | train_loss: 0.0184 | train_mae: nan | train_accuracy: 10.3422
  VAL        | val_loss: 0.0427 | val_mae: 0.1984 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.24it/s, batch_accuracy=30.00%, loss=0.0173, mae=nan]
Logging metrics: {'epoch': 97, 'train': {'train_loss': 0.018981031400679183, 'train_mae': nan, 'train_accuracy': 27.433460076045627}, 'val': {'val_loss': 0.0278197416985695, 'val_mae': 0.15881401300430298, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.018981031400679183, 'train_mae': nan, 'train_accuracy': 27.433460076045627}
splitting val
metrics {'val_loss': 0.0278197416985695, 'val_mae': 0.15881401300430298, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 96 Metrics:
  TRAIN      | train_loss: 0.0190 | train_mae: nan | train_accuracy: 27.4335
  VAL        | val_loss: 0.0278 | val_mae: 0.1588 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.10it/s, batch_accuracy=81.43%, loss=0.0036, mae=nan]
Logging metrics: {'epoch': 98, 'train': {'train_loss': 0.016198191955551052, 'train_mae': nan, 'train_accuracy': 24.277566539923953}, 'val': {'val_loss': 0.006037658993029754, 'val_mae': 0.06469419598579407, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.016198191955551052, 'train_mae': nan, 'train_accuracy': 24.277566539923953}
splitting val
metrics {'val_loss': 0.006037658993029754, 'val_mae': 0.06469419598579407, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 97 Metrics:
  TRAIN      | train_loss: 0.0162 | train_mae: nan | train_accuracy: 24.2776
  VAL        | val_loss: 0.0060 | val_mae: 0.0647 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.29it/s, batch_accuracy=64.29%, loss=0.0070, mae=nan]
Logging metrics: {'epoch': 99, 'train': {'train_loss': 0.00796003197939507, 'train_mae': nan, 'train_accuracy': 35.361216730038024}, 'val': {'val_loss': 0.017049659045113113, 'val_mae': 0.11847301572561264, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.00796003197939507, 'train_mae': nan, 'train_accuracy': 35.361216730038024}
splitting val
metrics {'val_loss': 0.017049659045113113, 'val_mae': 0.11847301572561264, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 98 Metrics:
  TRAIN      | train_loss: 0.0080 | train_mae: nan | train_accuracy: 35.3612
  VAL        | val_loss: 0.0170 | val_mae: 0.1185 | val_accuracy: 0.0000
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 44.35it/s, batch_accuracy=80.71%, loss=0.0035, mae=nan]
Logging metrics: {'epoch': 100, 'train': {'train_loss': 0.006629538557672795, 'train_mae': nan, 'train_accuracy': 32.56653992395437}, 'val': {'val_loss': 0.005869495230039344, 'val_mae': 0.06372715532779694, 'val_accuracy': 0.0}}
splitting train
metrics {'train_loss': 0.006629538557672795, 'train_mae': nan, 'train_accuracy': 32.56653992395437}
splitting val
metrics {'val_loss': 0.005869495230039344, 'val_mae': 0.06372715532779694, 'val_accuracy': 0.0}

ğŸ“ˆ Epoch 99 Metrics:
  TRAIN      | train_loss: 0.0066 | train_mae: nan | train_accuracy: 32.5665
  VAL        | val_loss: 0.0059 | val_mae: 0.0637 | val_accuracy: 0.0000
Using device: cuda
Overwriting config.yaml
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1052/1052 [00:00<00:00, 69044.20it/s]
tensor([[[7.5898e-02, 7.5837e-02, 7.9443e-02, 7.7210e-02, 1.6269e-01,
          0.0000e+00],
         [7.4396e-02, 6.9807e-02, 6.9779e-02, 6.4533e-02, 2.8832e-01,
          1.0000e+00],
         [6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         ...,
         [7.9146e-02, 7.6214e-02, 8.3466e-02, 8.0691e-02, 2.6502e-01,
          2.7000e+01],
         [7.9627e-02, 8.1279e-02, 8.7503e-02, 8.7414e-02, 2.8708e-01,
          2.8000e+01],
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01]],

        [[6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         [5.7941e-02, 6.1451e-02, 6.5809e-02, 6.6326e-02, 2.8905e-01,
          3.0000e+00],
         [6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         ...,
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01],
         [8.8543e-02, 8.5576e-02, 9.4177e-02, 9.1411e-02, 2.3793e-01,
          3.0000e+01],
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01]],

        [[6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         [7.7429e-02, 7.3169e-02, 7.6847e-02, 7.2698e-02, 2.3820e-01,
          5.0000e+00],
         [7.1600e-02, 6.8077e-02, 7.1544e-02, 6.7121e-02, 2.4884e-01,
          6.0000e+00],
         ...,
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01],
         [8.9478e-02, 8.5855e-02, 9.4510e-02, 9.0437e-02, 2.2472e-01,
          3.2000e+01],
         [8.8940e-02, 8.8709e-02, 9.2709e-02, 9.4767e-02, 2.2869e-01,
          3.3000e+01]],

        ...,

        [[7.5701e-01, 7.5232e-01, 7.5361e-01, 7.5220e-01, 4.1746e-01,
          2.0980e+03],
         [7.5774e-01, 7.7400e-01, 7.6588e-01, 7.7748e-01, 3.3292e-01,
          2.0990e+03],
         [7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         ...,
         [8.4790e-01, 8.5084e-01, 8.5497e-01, 8.5592e-01, 3.4319e-01,
          2.1250e+03],
         [8.5251e-01, 8.5637e-01, 8.5111e-01, 8.5713e-01, 3.4051e-01,
          2.1260e+03],
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03]],

        [[7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         [7.7104e-01, 7.6839e-01, 7.7663e-01, 7.7173e-01, 2.8959e-01,
          2.1010e+03],
         [7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         ...,
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03],
         [8.7764e-01, 8.7544e-01, 8.7454e-01, 8.6960e-01, 6.3964e-01,
          2.1280e+03],
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03]],

        [[7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         [7.7373e-01, 7.6921e-01, 7.7415e-01, 7.7559e-01, 2.8299e-01,
          2.1030e+03],
         [7.7585e-01, 7.7289e-01, 7.7073e-01, 7.7338e-01, 2.5774e-01,
          2.1040e+03],
         ...,
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03],
         [8.5712e-01, 8.5449e-01, 8.5862e-01, 8.5480e-01, 2.7797e-01,
          2.1300e+03],
         [8.4884e-01, 8.5315e-01, 8.5582e-01, 8.6026e-01, 2.5512e-01,
          2.1310e+03]]]) tensor([[[0.0914],
         [0.0912],
         [0.0904],
         [0.0948],
         [0.0946]],

        [[0.0904],
         [0.0948],
         [0.0946],
         [0.0965],
         [0.0960]],

        [[0.0946],
         [0.0965],
         [0.0960],
         [0.0949],
         [0.0928]],

        ...,

        [[0.8696],
         [0.8626],
         [0.8548],
         [0.8603],
         [0.8490]],

        [[0.8548],
         [0.8603],
         [0.8490],
         [0.8424],
         [0.8591]],

        [[0.8490],
         [0.8424],
         [0.8591],
         [0.8586],
         [0.8652]]])
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:00<00:00, 65481.07it/s]
tensor([[[6.5719e-01, 6.6361e-01, 6.4936e-01, 6.5925e-01, 4.0824e-01,
          1.8860e+03],
         [6.5551e-01, 6.6725e-01, 6.5389e-01, 6.7271e-01, 3.1687e-01,
          1.8870e+03],
         [6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         ...,
         [7.7402e-01, 7.7072e-01, 7.7510e-01, 7.7284e-01, 3.0145e-01,
          1.9130e+03],
         [7.9015e-01, 7.9554e-01, 7.9704e-01, 8.0242e-01, 3.7436e-01,
          1.9140e+03],
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03]],

        [[6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         [6.7267e-01, 6.8108e-01, 6.7317e-01, 6.7936e-01, 3.5958e-01,
          1.8890e+03],
         [6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         ...,
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03],
         [8.0496e-01, 8.1890e-01, 8.1136e-01, 8.2598e-01, 2.8704e-01,
          1.9160e+03],
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03]],

        [[6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         [6.9161e-01, 6.9709e-01, 6.9336e-01, 6.9766e-01, 2.5635e-01,
          1.8910e+03],
         [6.8915e-01, 6.8445e-01, 6.8591e-01, 6.8252e-01, 2.4504e-01,
          1.8920e+03],
         ...,
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03],
         [8.2698e-01, 8.3398e-01, 8.3088e-01, 8.3442e-01, 3.4946e-01,
          1.9180e+03],
         [8.2360e-01, 8.2621e-01, 8.2257e-01, 8.2392e-01, 2.9821e-01,
          1.9190e+03]],

        ...,

        [[1.3099e+00, 1.3105e+00, 1.3086e+00, 1.3087e+00, 2.6561e-01,
          2.4760e+03],
         [1.3089e+00, 1.3247e+00, 1.3172e+00, 1.3323e+00, 2.8477e-01,
          2.4770e+03],
         [1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         ...,
         [1.4274e+00, 1.4244e+00, 1.4280e+00, 1.4228e+00, 2.7436e-01,
          2.5030e+03],
         [1.4253e+00, 1.4240e+00, 1.4228e+00, 1.4228e+00, 2.6364e-01,
          2.5040e+03],
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03]],

        [[1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         [1.3846e+00, 1.3921e+00, 1.3930e+00, 1.3965e+00, 4.1811e-01,
          2.4790e+03],
         [1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         ...,
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03],
         [1.4201e+00, 1.4170e+00, 1.4226e+00, 1.4226e+00, 3.7419e-01,
          2.5060e+03],
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03]],

        [[1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         [1.4054e+00, 1.4034e+00, 1.4063e+00, 1.4060e+00, 3.4982e-01,
          2.4810e+03],
         [1.4036e+00, 1.4009e+00, 1.3973e+00, 1.4001e+00, 3.3950e-01,
          2.4820e+03],
         ...,
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03],
         [1.3730e+00, 1.3759e+00, 1.3657e+00, 1.3608e+00, 4.1479e-01,
          2.5080e+03],
         [1.3492e+00, 1.3915e+00, 1.3543e+00, 1.3822e+00, 7.9801e-01,
          2.5090e+03]]]) tensor([[[0.8260],
         [0.8317],
         [0.8344],
         [0.8239],
         [0.8272]],

        [[0.8344],
         [0.8239],
         [0.8272],
         [0.8086],
         [0.7781]],

        [[0.8272],
         [0.8086],
         [0.7781],
         [0.7750],
         [0.7790]],

        ...,

        [[1.4226],
         [1.3625],
         [1.3608],
         [1.3822],
         [1.3968]],

        [[1.3608],
         [1.3822],
         [1.3968],
         [1.4190],
         [1.4182]],

        [[1.3968],
         [1.4190],
         [1.4182],
         [1.3957],
         [1.3742]]])
6 1
Using device: cuda
Overwriting config.yaml
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1052/1052 [00:00<00:00, 70164.07it/s]
tensor([[[7.5898e-02, 7.5837e-02, 7.9443e-02, 7.7210e-02, 1.6269e-01,
          0.0000e+00],
         [7.4396e-02, 6.9807e-02, 6.9779e-02, 6.4533e-02, 2.8832e-01,
          1.0000e+00],
         [6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         ...,
         [7.9146e-02, 7.6214e-02, 8.3466e-02, 8.0691e-02, 2.6502e-01,
          2.7000e+01],
         [7.9627e-02, 8.1279e-02, 8.7503e-02, 8.7414e-02, 2.8708e-01,
          2.8000e+01],
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01]],

        [[6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         [5.7941e-02, 6.1451e-02, 6.5809e-02, 6.6326e-02, 2.8905e-01,
          3.0000e+00],
         [6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         ...,
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01],
         [8.8543e-02, 8.5576e-02, 9.4177e-02, 9.1411e-02, 2.3793e-01,
          3.0000e+01],
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01]],

        [[6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         [7.7429e-02, 7.3169e-02, 7.6847e-02, 7.2698e-02, 2.3820e-01,
          5.0000e+00],
         [7.1600e-02, 6.8077e-02, 7.1544e-02, 6.7121e-02, 2.4884e-01,
          6.0000e+00],
         ...,
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01],
         [8.9478e-02, 8.5855e-02, 9.4510e-02, 9.0437e-02, 2.2472e-01,
          3.2000e+01],
         [8.8940e-02, 8.8709e-02, 9.2709e-02, 9.4767e-02, 2.2869e-01,
          3.3000e+01]],

        ...,

        [[7.5701e-01, 7.5232e-01, 7.5361e-01, 7.5220e-01, 4.1746e-01,
          2.0980e+03],
         [7.5774e-01, 7.7400e-01, 7.6588e-01, 7.7748e-01, 3.3292e-01,
          2.0990e+03],
         [7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         ...,
         [8.4790e-01, 8.5084e-01, 8.5497e-01, 8.5592e-01, 3.4319e-01,
          2.1250e+03],
         [8.5251e-01, 8.5637e-01, 8.5111e-01, 8.5713e-01, 3.4051e-01,
          2.1260e+03],
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03]],

        [[7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         [7.7104e-01, 7.6839e-01, 7.7663e-01, 7.7173e-01, 2.8959e-01,
          2.1010e+03],
         [7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         ...,
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03],
         [8.7764e-01, 8.7544e-01, 8.7454e-01, 8.6960e-01, 6.3964e-01,
          2.1280e+03],
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03]],

        [[7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         [7.7373e-01, 7.6921e-01, 7.7415e-01, 7.7559e-01, 2.8299e-01,
          2.1030e+03],
         [7.7585e-01, 7.7289e-01, 7.7073e-01, 7.7338e-01, 2.5774e-01,
          2.1040e+03],
         ...,
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03],
         [8.5712e-01, 8.5449e-01, 8.5862e-01, 8.5480e-01, 2.7797e-01,
          2.1300e+03],
         [8.4884e-01, 8.5315e-01, 8.5582e-01, 8.6026e-01, 2.5512e-01,
          2.1310e+03]]]) tensor([[[0.0914],
         [0.0912],
         [0.0904],
         [0.0948],
         [0.0946]],

        [[0.0904],
         [0.0948],
         [0.0946],
         [0.0965],
         [0.0960]],

        [[0.0946],
         [0.0965],
         [0.0960],
         [0.0949],
         [0.0928]],

        ...,

        [[0.8696],
         [0.8626],
         [0.8548],
         [0.8603],
         [0.8490]],

        [[0.8548],
         [0.8603],
         [0.8490],
         [0.8424],
         [0.8591]],

        [[0.8490],
         [0.8424],
         [0.8591],
         [0.8586],
         [0.8652]]])
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:00<00:00, 67011.72it/s]
tensor([[[6.5719e-01, 6.6361e-01, 6.4936e-01, 6.5925e-01, 4.0824e-01,
          1.8860e+03],
         [6.5551e-01, 6.6725e-01, 6.5389e-01, 6.7271e-01, 3.1687e-01,
          1.8870e+03],
         [6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         ...,
         [7.7402e-01, 7.7072e-01, 7.7510e-01, 7.7284e-01, 3.0145e-01,
          1.9130e+03],
         [7.9015e-01, 7.9554e-01, 7.9704e-01, 8.0242e-01, 3.7436e-01,
          1.9140e+03],
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03]],

        [[6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         [6.7267e-01, 6.8108e-01, 6.7317e-01, 6.7936e-01, 3.5958e-01,
          1.8890e+03],
         [6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         ...,
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03],
         [8.0496e-01, 8.1890e-01, 8.1136e-01, 8.2598e-01, 2.8704e-01,
          1.9160e+03],
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03]],

        [[6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         [6.9161e-01, 6.9709e-01, 6.9336e-01, 6.9766e-01, 2.5635e-01,
          1.8910e+03],
         [6.8915e-01, 6.8445e-01, 6.8591e-01, 6.8252e-01, 2.4504e-01,
          1.8920e+03],
         ...,
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03],
         [8.2698e-01, 8.3398e-01, 8.3088e-01, 8.3442e-01, 3.4946e-01,
          1.9180e+03],
         [8.2360e-01, 8.2621e-01, 8.2257e-01, 8.2392e-01, 2.9821e-01,
          1.9190e+03]],

        ...,

        [[1.3099e+00, 1.3105e+00, 1.3086e+00, 1.3087e+00, 2.6561e-01,
          2.4760e+03],
         [1.3089e+00, 1.3247e+00, 1.3172e+00, 1.3323e+00, 2.8477e-01,
          2.4770e+03],
         [1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         ...,
         [1.4274e+00, 1.4244e+00, 1.4280e+00, 1.4228e+00, 2.7436e-01,
          2.5030e+03],
         [1.4253e+00, 1.4240e+00, 1.4228e+00, 1.4228e+00, 2.6364e-01,
          2.5040e+03],
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03]],

        [[1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         [1.3846e+00, 1.3921e+00, 1.3930e+00, 1.3965e+00, 4.1811e-01,
          2.4790e+03],
         [1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         ...,
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03],
         [1.4201e+00, 1.4170e+00, 1.4226e+00, 1.4226e+00, 3.7419e-01,
          2.5060e+03],
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03]],

        [[1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         [1.4054e+00, 1.4034e+00, 1.4063e+00, 1.4060e+00, 3.4982e-01,
          2.4810e+03],
         [1.4036e+00, 1.4009e+00, 1.3973e+00, 1.4001e+00, 3.3950e-01,
          2.4820e+03],
         ...,
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03],
         [1.3730e+00, 1.3759e+00, 1.3657e+00, 1.3608e+00, 4.1479e-01,
          2.5080e+03],
         [1.3492e+00, 1.3915e+00, 1.3543e+00, 1.3822e+00, 7.9801e-01,
          2.5090e+03]]]) tensor([[[0.8260],
         [0.8317],
         [0.8344],
         [0.8239],
         [0.8272]],

        [[0.8344],
         [0.8239],
         [0.8272],
         [0.8086],
         [0.7781]],

        [[0.8272],
         [0.8086],
         [0.7781],
         [0.7750],
         [0.7790]],

        ...,

        [[1.4226],
         [1.3625],
         [1.3608],
         [1.3822],
         [1.3968]],

        [[1.3608],
         [1.3822],
         [1.3968],
         [1.4190],
         [1.4182]],

        [[1.3968],
         [1.4190],
         [1.4182],
         [1.3957],
         [1.3742]]])
6 1
6 1
Using device: cuda
Overwriting config.yaml
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1052/1052 [00:00<00:00, 67655.25it/s]
tensor([[[7.5898e-02, 7.5837e-02, 7.9443e-02, 7.7210e-02, 1.6269e-01,
          0.0000e+00],
         [7.4396e-02, 6.9807e-02, 6.9779e-02, 6.4533e-02, 2.8832e-01,
          1.0000e+00],
         [6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         ...,
         [7.9146e-02, 7.6214e-02, 8.3466e-02, 8.0691e-02, 2.6502e-01,
          2.7000e+01],
         [7.9627e-02, 8.1279e-02, 8.7503e-02, 8.7414e-02, 2.8708e-01,
          2.8000e+01],
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01]],

        [[6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         [5.7941e-02, 6.1451e-02, 6.5809e-02, 6.6326e-02, 2.8905e-01,
          3.0000e+00],
         [6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         ...,
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01],
         [8.8543e-02, 8.5576e-02, 9.4177e-02, 9.1411e-02, 2.3793e-01,
          3.0000e+01],
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01]],

        [[6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         [7.7429e-02, 7.3169e-02, 7.6847e-02, 7.2698e-02, 2.3820e-01,
          5.0000e+00],
         [7.1600e-02, 6.8077e-02, 7.1544e-02, 6.7121e-02, 2.4884e-01,
          6.0000e+00],
         ...,
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01],
         [8.9478e-02, 8.5855e-02, 9.4510e-02, 9.0437e-02, 2.2472e-01,
          3.2000e+01],
         [8.8940e-02, 8.8709e-02, 9.2709e-02, 9.4767e-02, 2.2869e-01,
          3.3000e+01]],

        ...,

        [[7.5701e-01, 7.5232e-01, 7.5361e-01, 7.5220e-01, 4.1746e-01,
          2.0980e+03],
         [7.5774e-01, 7.7400e-01, 7.6588e-01, 7.7748e-01, 3.3292e-01,
          2.0990e+03],
         [7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         ...,
         [8.4790e-01, 8.5084e-01, 8.5497e-01, 8.5592e-01, 3.4319e-01,
          2.1250e+03],
         [8.5251e-01, 8.5637e-01, 8.5111e-01, 8.5713e-01, 3.4051e-01,
          2.1260e+03],
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03]],

        [[7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         [7.7104e-01, 7.6839e-01, 7.7663e-01, 7.7173e-01, 2.8959e-01,
          2.1010e+03],
         [7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         ...,
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03],
         [8.7764e-01, 8.7544e-01, 8.7454e-01, 8.6960e-01, 6.3964e-01,
          2.1280e+03],
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03]],

        [[7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         [7.7373e-01, 7.6921e-01, 7.7415e-01, 7.7559e-01, 2.8299e-01,
          2.1030e+03],
         [7.7585e-01, 7.7289e-01, 7.7073e-01, 7.7338e-01, 2.5774e-01,
          2.1040e+03],
         ...,
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03],
         [8.5712e-01, 8.5449e-01, 8.5862e-01, 8.5480e-01, 2.7797e-01,
          2.1300e+03],
         [8.4884e-01, 8.5315e-01, 8.5582e-01, 8.6026e-01, 2.5512e-01,
          2.1310e+03]]]) tensor([[[0.0914],
         [0.0912],
         [0.0904],
         [0.0948],
         [0.0946]],

        [[0.0904],
         [0.0948],
         [0.0946],
         [0.0965],
         [0.0960]],

        [[0.0946],
         [0.0965],
         [0.0960],
         [0.0949],
         [0.0928]],

        ...,

        [[0.8696],
         [0.8626],
         [0.8548],
         [0.8603],
         [0.8490]],

        [[0.8548],
         [0.8603],
         [0.8490],
         [0.8424],
         [0.8591]],

        [[0.8490],
         [0.8424],
         [0.8591],
         [0.8586],
         [0.8652]]])
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:00<00:00, 70120.76it/s]
tensor([[[6.5719e-01, 6.6361e-01, 6.4936e-01, 6.5925e-01, 4.0824e-01,
          1.8860e+03],
         [6.5551e-01, 6.6725e-01, 6.5389e-01, 6.7271e-01, 3.1687e-01,
          1.8870e+03],
         [6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         ...,
         [7.7402e-01, 7.7072e-01, 7.7510e-01, 7.7284e-01, 3.0145e-01,
          1.9130e+03],
         [7.9015e-01, 7.9554e-01, 7.9704e-01, 8.0242e-01, 3.7436e-01,
          1.9140e+03],
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03]],

        [[6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         [6.7267e-01, 6.8108e-01, 6.7317e-01, 6.7936e-01, 3.5958e-01,
          1.8890e+03],
         [6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         ...,
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03],
         [8.0496e-01, 8.1890e-01, 8.1136e-01, 8.2598e-01, 2.8704e-01,
          1.9160e+03],
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03]],

        [[6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         [6.9161e-01, 6.9709e-01, 6.9336e-01, 6.9766e-01, 2.5635e-01,
          1.8910e+03],
         [6.8915e-01, 6.8445e-01, 6.8591e-01, 6.8252e-01, 2.4504e-01,
          1.8920e+03],
         ...,
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03],
         [8.2698e-01, 8.3398e-01, 8.3088e-01, 8.3442e-01, 3.4946e-01,
          1.9180e+03],
         [8.2360e-01, 8.2621e-01, 8.2257e-01, 8.2392e-01, 2.9821e-01,
          1.9190e+03]],

        ...,

        [[1.3099e+00, 1.3105e+00, 1.3086e+00, 1.3087e+00, 2.6561e-01,
          2.4760e+03],
         [1.3089e+00, 1.3247e+00, 1.3172e+00, 1.3323e+00, 2.8477e-01,
          2.4770e+03],
         [1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         ...,
         [1.4274e+00, 1.4244e+00, 1.4280e+00, 1.4228e+00, 2.7436e-01,
          2.5030e+03],
         [1.4253e+00, 1.4240e+00, 1.4228e+00, 1.4228e+00, 2.6364e-01,
          2.5040e+03],
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03]],

        [[1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         [1.3846e+00, 1.3921e+00, 1.3930e+00, 1.3965e+00, 4.1811e-01,
          2.4790e+03],
         [1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         ...,
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03],
         [1.4201e+00, 1.4170e+00, 1.4226e+00, 1.4226e+00, 3.7419e-01,
          2.5060e+03],
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03]],

        [[1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         [1.4054e+00, 1.4034e+00, 1.4063e+00, 1.4060e+00, 3.4982e-01,
          2.4810e+03],
         [1.4036e+00, 1.4009e+00, 1.3973e+00, 1.4001e+00, 3.3950e-01,
          2.4820e+03],
         ...,
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03],
         [1.3730e+00, 1.3759e+00, 1.3657e+00, 1.3608e+00, 4.1479e-01,
          2.5080e+03],
         [1.3492e+00, 1.3915e+00, 1.3543e+00, 1.3822e+00, 7.9801e-01,
          2.5090e+03]]]) tensor([[[0.8260],
         [0.8317],
         [0.8344],
         [0.8239],
         [0.8272]],

        [[0.8344],
         [0.8239],
         [0.8272],
         [0.8086],
         [0.7781]],

        [[0.8272],
         [0.8086],
         [0.7781],
         [0.7750],
         [0.7790]],

        ...,

        [[1.4226],
         [1.3625],
         [1.3608],
         [1.3822],
         [1.3968]],

        [[1.3608],
         [1.3822],
         [1.3968],
         [1.4190],
         [1.4182]],

        [[1.3968],
         [1.4190],
         [1.4182],
         [1.3957],
         [1.3742]]])
6 1
Using device: cuda
Overwriting config.yaml
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (train): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1052/1052 [00:00<00:00, 68580.61it/s]
tensor([[[7.5898e-02, 7.5837e-02, 7.9443e-02, 7.7210e-02, 1.6269e-01,
          0.0000e+00],
         [7.4396e-02, 6.9807e-02, 6.9779e-02, 6.4533e-02, 2.8832e-01,
          1.0000e+00],
         [6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         ...,
         [7.9146e-02, 7.6214e-02, 8.3466e-02, 8.0691e-02, 2.6502e-01,
          2.7000e+01],
         [7.9627e-02, 8.1279e-02, 8.7503e-02, 8.7414e-02, 2.8708e-01,
          2.8000e+01],
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01]],

        [[6.3528e-02, 6.1667e-02, 6.1395e-02, 5.8477e-02, 3.6447e-01,
          2.0000e+00],
         [5.7941e-02, 6.1451e-02, 6.5809e-02, 6.6326e-02, 2.8905e-01,
          3.0000e+00],
         [6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         ...,
         [8.5954e-02, 8.4139e-02, 9.3133e-02, 9.0282e-02, 2.5702e-01,
          2.9000e+01],
         [8.8543e-02, 8.5576e-02, 9.4177e-02, 9.1411e-02, 2.3793e-01,
          3.0000e+01],
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01]],

        [[6.6376e-02, 7.3051e-02, 7.4247e-02, 7.8538e-02, 3.0386e-01,
          4.0000e+00],
         [7.7429e-02, 7.3169e-02, 7.6847e-02, 7.2698e-02, 2.3820e-01,
          5.0000e+00],
         [7.1600e-02, 6.8077e-02, 7.1544e-02, 6.7121e-02, 2.4884e-01,
          6.0000e+00],
         ...,
         [8.9448e-02, 8.5216e-02, 9.4968e-02, 9.1188e-02, 2.3888e-01,
          3.1000e+01],
         [8.9478e-02, 8.5855e-02, 9.4510e-02, 9.0437e-02, 2.2472e-01,
          3.2000e+01],
         [8.8940e-02, 8.8709e-02, 9.2709e-02, 9.4767e-02, 2.2869e-01,
          3.3000e+01]],

        ...,

        [[7.5701e-01, 7.5232e-01, 7.5361e-01, 7.5220e-01, 4.1746e-01,
          2.0980e+03],
         [7.5774e-01, 7.7400e-01, 7.6588e-01, 7.7748e-01, 3.3292e-01,
          2.0990e+03],
         [7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         ...,
         [8.4790e-01, 8.5084e-01, 8.5497e-01, 8.5592e-01, 3.4319e-01,
          2.1250e+03],
         [8.5251e-01, 8.5637e-01, 8.5111e-01, 8.5713e-01, 3.4051e-01,
          2.1260e+03],
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03]],

        [[7.7533e-01, 7.7241e-01, 7.7904e-01, 7.7811e-01, 2.7017e-01,
          2.1000e+03],
         [7.7104e-01, 7.6839e-01, 7.7663e-01, 7.7173e-01, 2.8959e-01,
          2.1010e+03],
         [7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         ...,
         [8.5218e-01, 8.7232e-01, 8.5944e-01, 8.7507e-01, 3.3182e-01,
          2.1270e+03],
         [8.7764e-01, 8.7544e-01, 8.7454e-01, 8.6960e-01, 6.3964e-01,
          2.1280e+03],
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03]],

        [[7.7760e-01, 7.7644e-01, 7.7066e-01, 7.7795e-01, 3.1805e-01,
          2.1020e+03],
         [7.7373e-01, 7.6921e-01, 7.7415e-01, 7.7559e-01, 2.8299e-01,
          2.1030e+03],
         [7.7585e-01, 7.7289e-01, 7.7073e-01, 7.7338e-01, 2.5774e-01,
          2.1040e+03],
         ...,
         [8.6254e-01, 8.5918e-01, 8.6099e-01, 8.6256e-01, 3.1789e-01,
          2.1290e+03],
         [8.5712e-01, 8.5449e-01, 8.5862e-01, 8.5480e-01, 2.7797e-01,
          2.1300e+03],
         [8.4884e-01, 8.5315e-01, 8.5582e-01, 8.6026e-01, 2.5512e-01,
          2.1310e+03]]]) tensor([[[0.0914],
         [0.0912],
         [0.0904],
         [0.0948],
         [0.0946]],

        [[0.0904],
         [0.0948],
         [0.0946],
         [0.0965],
         [0.0960]],

        [[0.0946],
         [0.0965],
         [0.0960],
         [0.0949],
         [0.0928]],

        ...,

        [[0.8696],
         [0.8626],
         [0.8548],
         [0.8603],
         [0.8490]],

        [[0.8548],
         [0.8603],
         [0.8490],
         [0.8424],
         [0.8591]],

        [[0.8490],
         [0.8424],
         [0.8591],
         [0.8586],
         [0.8652]]])
[*********************100%***********************]  1 of 1 completed
Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Time'], dtype='object')
Processing ^SPX (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:00<00:00, 65133.02it/s]
tensor([[[6.5719e-01, 6.6361e-01, 6.4936e-01, 6.5925e-01, 4.0824e-01,
          1.8860e+03],
         [6.5551e-01, 6.6725e-01, 6.5389e-01, 6.7271e-01, 3.1687e-01,
          1.8870e+03],
         [6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         ...,
         [7.7402e-01, 7.7072e-01, 7.7510e-01, 7.7284e-01, 3.0145e-01,
          1.9130e+03],
         [7.9015e-01, 7.9554e-01, 7.9704e-01, 8.0242e-01, 3.7436e-01,
          1.9140e+03],
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03]],

        [[6.5942e-01, 6.6805e-01, 6.5050e-01, 6.7475e-01, 4.3549e-01,
          1.8880e+03],
         [6.7267e-01, 6.8108e-01, 6.7317e-01, 6.7936e-01, 3.5958e-01,
          1.8890e+03],
         [6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         ...,
         [8.0576e-01, 8.1131e-01, 8.0517e-01, 8.0142e-01, 3.8406e-01,
          1.9150e+03],
         [8.0496e-01, 8.1890e-01, 8.1136e-01, 8.2598e-01, 2.8704e-01,
          1.9160e+03],
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03]],

        [[6.8172e-01, 6.9445e-01, 6.8983e-01, 6.9875e-01, 3.1812e-01,
          1.8900e+03],
         [6.9161e-01, 6.9709e-01, 6.9336e-01, 6.9766e-01, 2.5635e-01,
          1.8910e+03],
         [6.8915e-01, 6.8445e-01, 6.8591e-01, 6.8252e-01, 2.4504e-01,
          1.8920e+03],
         ...,
         [8.1989e-01, 8.2608e-01, 8.2385e-01, 8.3170e-01, 2.7653e-01,
          1.9170e+03],
         [8.2698e-01, 8.3398e-01, 8.3088e-01, 8.3442e-01, 3.4946e-01,
          1.9180e+03],
         [8.2360e-01, 8.2621e-01, 8.2257e-01, 8.2392e-01, 2.9821e-01,
          1.9190e+03]],

        ...,

        [[1.3099e+00, 1.3105e+00, 1.3086e+00, 1.3087e+00, 2.6561e-01,
          2.4760e+03],
         [1.3089e+00, 1.3247e+00, 1.3172e+00, 1.3323e+00, 2.8477e-01,
          2.4770e+03],
         [1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         ...,
         [1.4274e+00, 1.4244e+00, 1.4280e+00, 1.4228e+00, 2.7436e-01,
          2.5030e+03],
         [1.4253e+00, 1.4240e+00, 1.4228e+00, 1.4228e+00, 2.6364e-01,
          2.5040e+03],
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03]],

        [[1.3569e+00, 1.3761e+00, 1.3653e+00, 1.3816e+00, 5.7984e-01,
          2.4780e+03],
         [1.3846e+00, 1.3921e+00, 1.3930e+00, 1.3965e+00, 4.1811e-01,
          2.4790e+03],
         [1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         ...,
         [1.4238e+00, 1.4262e+00, 1.4307e+00, 1.4305e+00, 3.5652e-01,
          2.5050e+03],
         [1.4201e+00, 1.4170e+00, 1.4226e+00, 1.4226e+00, 3.7419e-01,
          2.5060e+03],
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03]],

        [[1.3945e+00, 1.4017e+00, 1.4029e+00, 1.4040e+00, 3.8827e-01,
          2.4800e+03],
         [1.4054e+00, 1.4034e+00, 1.4063e+00, 1.4060e+00, 3.4982e-01,
          2.4810e+03],
         [1.4036e+00, 1.4009e+00, 1.3973e+00, 1.4001e+00, 3.3950e-01,
          2.4820e+03],
         ...,
         [1.4184e+00, 1.4213e+00, 1.3663e+00, 1.3625e+00, 4.5512e-01,
          2.5070e+03],
         [1.3730e+00, 1.3759e+00, 1.3657e+00, 1.3608e+00, 4.1479e-01,
          2.5080e+03],
         [1.3492e+00, 1.3915e+00, 1.3543e+00, 1.3822e+00, 7.9801e-01,
          2.5090e+03]]]) tensor([[[0.8260],
         [0.8317],
         [0.8344],
         [0.8239],
         [0.8272]],

        [[0.8344],
         [0.8239],
         [0.8272],
         [0.8086],
         [0.7781]],

        [[0.8272],
         [0.8086],
         [0.7781],
         [0.7750],
         [0.7790]],

        ...,

        [[1.4226],
         [1.3625],
         [1.3608],
         [1.3822],
         [1.3968]],

        [[1.3608],
         [1.3822],
         [1.3968],
         [1.4190],
         [1.4182]],

        [[1.3968],
         [1.4190],
         [1.4182],
         [1.3957],
         [1.3742]]])
6 1
First input sample (shape: torch.Size([30, 6])):
tensor([[ 0.0759,  0.0758,  0.0794,  0.0772,  0.1627,  0.0000],
        [ 0.0744,  0.0698,  0.0698,  0.0645,  0.2883,  1.0000],
        [ 0.0635,  0.0617,  0.0614,  0.0585,  0.3645,  2.0000],
        [ 0.0579,  0.0615,  0.0658,  0.0663,  0.2890,  3.0000],
        [ 0.0664,  0.0731,  0.0742,  0.0785,  0.3039,  4.0000],
        [ 0.0774,  0.0732,  0.0768,  0.0727,  0.2382,  5.0000],
        [ 0.0716,  0.0681,  0.0715,  0.0671,  0.2488,  6.0000],
        [ 0.0667,  0.0706,  0.0667,  0.0654,  0.3238,  7.0000],
        [ 0.0623,  0.0577,  0.0600,  0.0614,  0.3551,  8.0000],
        [ 0.0607,  0.0587,  0.0611,  0.0551,  0.3433,  9.0000],
        [ 0.0535,  0.0584,  0.0599,  0.0641,  0.3180, 10.0000],
        [ 0.0631,  0.0612,  0.0655,  0.0652,  0.3050, 11.0000],
        [ 0.0629,  0.0644,  0.0680,  0.0684,  0.2804, 12.0000],
        [ 0.0676,  0.0732,  0.0728,  0.0789,  0.3317, 13.0000],
        [ 0.0773,  0.0727,  0.0810,  0.0751,  0.2623, 14.0000],
        [ 0.0730,  0.0709,  0.0777,  0.0768,  0.2499, 15.0000],
        [ 0.0722,  0.0676,  0.0706,  0.0676,  0.2342, 16.0000],
        [ 0.0670,  0.0658,  0.0644,  0.0583,  0.3192, 17.0000],
        [ 0.0569,  0.0598,  0.0603,  0.0648,  0.3261, 18.0000],
        [ 0.0626,  0.0593,  0.0617,  0.0559,  0.3770, 19.0000],
        [ 0.0550,  0.0588,  0.0575,  0.0646,  0.3124, 20.0000],
        [ 0.0637,  0.0684,  0.0716,  0.0745,  0.3824, 21.0000],
        [ 0.0725,  0.0699,  0.0763,  0.0716,  0.3278, 22.0000],
        [ 0.0707,  0.0729,  0.0786,  0.0787,  0.2910, 23.0000],
        [ 0.0770,  0.0759,  0.0808,  0.0763,  0.3383, 24.0000],
        [ 0.0741,  0.0704,  0.0780,  0.0733,  0.2596, 25.0000],
        [ 0.0727,  0.0753,  0.0803,  0.0807,  0.2734, 26.0000],
        [ 0.0791,  0.0762,  0.0835,  0.0807,  0.2650, 27.0000],
        [ 0.0796,  0.0813,  0.0875,  0.0874,  0.2871, 28.0000],
        [ 0.0860,  0.0841,  0.0931,  0.0903,  0.2570, 29.0000]])
Corresponding target (shape: torch.Size([5, 1])):
tensor([[0.0914],
        [0.0912],
        [0.0904],
        [0.0948],
        [0.0946]])
Inputs: torch.Size([64, 30, 6])
Targets: torch.Size([64, 5, 1])
torch.Size([64, 5, 1])
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
TimeSeriesTransformer                         [64, 5, 1]                --
â”œâ”€Linear: 1-1                                 [64, 30, 256]             1,536
â”œâ”€GELU: 1-2                                   [64, 30, 256]             --
â”œâ”€Time2VecTorch: 1-3                          [64, 30, 4]               8
â”œâ”€TimeSeriesPositionalEncoding: 1-4           [64, 30, 260]             --
â”œâ”€Dropout: 1-5                                [64, 30, 260]             --
â”œâ”€Linear: 1-6                                 [64, 5, 256]              512
â”œâ”€Time2VecTorch: 1-7                          [64, 5, 4]                (recursive)
â”œâ”€TimeSeriesPositionalEncoding: 1-8           [64, 5, 260]              --
â”œâ”€Dropout: 1-9                                [64, 5, 260]              --
â”œâ”€TransformerDecoder: 1-10                    [64, 5, 260]              --
â”‚    â””â”€ModuleList: 2-1                        --                        --
â”‚    â”‚    â””â”€TransformerDecoderLayer: 3-1      [64, 5, 260]              578,044
â”‚    â”‚    â””â”€TransformerDecoderLayer: 3-2      [64, 5, 260]              578,044
â”œâ”€LayerNorm: 1-11                             [64, 5, 260]              520
â”œâ”€Linear: 1-12                                [64, 5, 1]                261
===============================================================================================
Total params: 1,158,925
Trainable params: 1,158,925
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 4.68
===============================================================================================
Input size (MB): 0.05
Forward/backward pass size (MB): 10.98
Params size (MB): 0.29
Estimated Total Size (MB): 11.32
===============================================================================================
[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.login() after wandb.init() has no effect.
True
done with init!
here!

ğŸ”§ Configuring Optimizer:
â”œâ”€â”€ Type: ADAMW
â”œâ”€â”€ Base LR: 0.0005
â”œâ”€â”€ Weight Decay: 0.0001
â”œâ”€â”€ Parameter Groups:
â”‚   â”œâ”€â”€ Group: self_attn
â”‚   â”‚   â”œâ”€â”€ LR: 0.0001
â”‚   â”‚   â””â”€â”€ Patterns: []
â”‚   â”œâ”€â”€ Group: ffn
â”‚   â”‚   â”œâ”€â”€ LR: 0.0001
â”‚   â”‚   â””â”€â”€ Patterns: []
â”‚   â””â”€â”€ Default Group (unmatched parameters)
â””â”€â”€ AdamW Specific:
    â”œâ”€â”€ Betas: [0.9, 0.999]
    â”œâ”€â”€ Epsilon: 1e-08
    â””â”€â”€ AMSGrad: False

ğŸ“ˆ Configuring Learning Rate Scheduler:
â”œâ”€â”€ Type: COSINE
â”œâ”€â”€ Cosine Annealing Settings:
â”‚   â”œâ”€â”€ T_max: 15 epochs (255 steps)
â”‚   â””â”€â”€ Min LR: 1e-08
â”œâ”€â”€ Warmup Settings:
â”‚   â”œâ”€â”€ Duration: 5 epochs (85 steps)
â”‚   â”œâ”€â”€ Start Factor: 0.1
â”‚   â””â”€â”€ End Factor: 1.0
Warning: Only showing 5 out of 48 parameter groups for clarity
/jet/home/psamal/hw_envs/idl_hw4/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
