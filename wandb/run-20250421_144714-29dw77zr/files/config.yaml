_wandb:
    value:
        cli_version: 0.19.9
        m: []
        python_version: 3.12.4
        t:
            "1":
                - 1
                - 5
                - 53
                - 55
            "2":
                - 1
                - 5
                - 53
                - 55
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.12.4
            "5": 0.19.9
            "8":
                - 1
                - 8
            "12": 0.19.9
            "13": linux-x86_64
Name:
    value: Nayesha-Gopal
data:
    value:
        NUM_WORKERS: 2
        batch_size: 64
        forecast_horizon: 1
        root: /local/hw4_data/hw4p1_data
        subset: 1
        test_partition: test
        train_partition: train
        val_partition: val
loss:
    value:
        label_smoothing: 0
model:
    value:
        d_ff: 64
        d_freq: 3
        d_model: 128
        dropout: 0.4
        forecast_horizon: 1
        input_features: 6
        num_heads: 66
        num_layers: 2
        output_features: 1
optimizer:
    value:
        adam:
            amsgrad: false
            betas:
                - 0.9
                - 0.999
            eps: 1e-08
        adamw:
            amsgrad: false
            betas:
                - 0.9
                - 0.999
            eps: 1e-08
        layer_decay:
            decay_rate: 0.75
            enabled: false
        lr: 0.0005
        name: adamw
        param_groups:
            - layer_decay:
                decay_rate: 0.8
                enabled: false
              lr: 0.0001
              name: self_attn
              patterns: []
            - layer_decay:
                decay_rate: 0.8
                enabled: false
              lr: 0.0001
              name: ffn
              patterns: []
        sgd:
            dampening: 0
            momentum: 0.9
            nesterov: true
        weight_decay: 0.0001
scheduler:
    value:
        cosine:
            T_max: 15
            eta_min: 1e-08
            last_epoch: -1
        cosine_warm:
            T_0: 4
            T_mult: 4
            eta_min: 1e-07
            last_epoch: -1
        name: cosine
        reduce_lr:
            cooldown: 0
            eps: 1e-08
            factor: 0.1
            min_lr: 1e-07
            mode: min
            patience: 10
            threshold: 0.0001
            threshold_mode: rel
        warmup:
            enabled: true
            end_factor: 1
            epochs: 5
            start_factor: 0.1
            type: exponential
training:
    value:
        epochs: 10
        gradient_accumulation_steps: 1
        resume: false
        use_wandb: true
        wandb_project: IDL_final project PegasusNG
        wandb_run_id: none
